{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mura_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "up1iA_3xOwax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
        "!unzip MURA-v1.1.zip\n",
        "!rm MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMY_KstJs079",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall keras\n",
        "!pip3 install git+https://github.com/keras-team/keras\n",
        "!pip uninstall keras-preprocessing\n",
        "!pip3 install git+https://github.com/keras-team/keras-preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rdHciFEs2Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "#RESTART RUNTIME BEFORE PROCEEDING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_91u16WOSr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, signal, shutil\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras import backend as K\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ez9S9xLB0yIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# onlyfiles = [f for f in listdir(\"MURA-v1.1\")]\n",
        "# print(onlyfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N790OUoYiuDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SETUP"
      ]
    },
    {
      "metadata": {
        "id": "_FjBSeR09-UZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# just run the cell to be able to upload and download from Dropbox\n",
        "!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
        "!chmod +x Dropbox-Uploader/dropbox_uploader.sh\n",
        "source = 'Dropbox-Uploader'\n",
        "dest1 = '/content'\n",
        "shutil.move(source+'/'+'dropbox_uploader.sh', dest1)\n",
        "!echo \"pzFqTa1uWVAAAAAAAAAACtGcVohdBzoFRrwtLYsQCxhD9a7IjevvuOTNV8OWB2LX\" > token.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTqlisSN_xe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh download README.md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBG6GG75QHwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download train and valid csv files that include images path and their labels\n",
        "!bash dropbox_uploader.sh download train_paths_labels.csv\n",
        "!bash dropbox_uploader.sh download valid_paths_labels.csv\n",
        "# the saved model file\n",
        "model_file= 'model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Cu15H_TCAVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# watch_ monitors the state of certain file if it is modified and uploads it to Dropbox if so\n",
        "def watch_(file, interval):\n",
        "  from datetime import datetime\n",
        "  first_Time=False\n",
        "  while True:\n",
        "    if os.path.isfile(file):\n",
        "      if not first_Time:\n",
        "        os.system(\"bash dropbox_uploader.sh upload \"+file+\" \"+file)\n",
        "        first_Time=True\n",
        "      moddate = os.stat(file)[8]\n",
        "      time.sleep(interval)\n",
        "      moddate_ = os.stat(file)[8]\n",
        "      if moddate < moddate_:\n",
        "        os.system(\"bash dropbox_uploader.sh upload \"+file+\" \"+file)\n",
        "    else:\n",
        "      time.sleep(interval)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbXWb8jCVsGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ]
    },
    {
      "metadata": {
        "id": "4Y4fjRr9Vwl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  #weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  #default because refrenced before assignment error, just scroll down\n",
        "  base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  \n",
        "  #initializing pretrained model\n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 3):\n",
        "    base_model = ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False)   \n",
        "  elif (base == 4):\n",
        "    base_model = NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "    \n",
        " \n",
        "  if (freeze_all):\n",
        "    #freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "  # add a global spatial average pooling layer\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  \n",
        "  if(add_denses):\n",
        "    # let's add a fully-connected layer\n",
        "    #x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    #x = Dense(32, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have 200 classes\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # just feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2nG7OGT2iwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "bug: if called fn on another base model it still loads the model"
      ]
    },
    {
      "metadata": {
        "id": "1FlPKw5LXEOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv')\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "  datagen=ImageDataGenerator(rescale=1./255)\n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(32,32), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(32,32), batch_size=batch)\n",
        "  print(len(train_generator))\n",
        "  print(\"making model\")\n",
        "  if not os.path.isfile(model_file):\n",
        "    model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "  else:\n",
        "    model= load_model(model_file)\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=False,\n",
        "                              save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch, validation_data=valid_generator, validation_steps=step_valid, shuffle=True, verbose=verbose, callbacks=callbacks_list)\n",
        "   #\n",
        "  \n",
        "  \n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,steps=step_train)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,steps=step_valid)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEX9fTsAO5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #KAREEM'S COPY OF FUNCTION JUST COMMENT THE CELL AND EVERYTHING IS NORMAL\n",
        "# def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "#   df_train=pd.read_csv('train_paths_labels.csv')\n",
        "#   df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "#   datagen = ImageDataGenerator(  rescale=1./255,\n",
        "#     featurewise_center=True,  #CHANGED IT TO TRUE # set input mean to 0 over the dataset\n",
        "#     samplewise_center=False,  # set each sample mean to 0\n",
        "#     featurewise_std_normalization=True,  #CHANGED IT TO TRUE# divide inputs by std of the dataset\n",
        "#     samplewise_std_normalization=False,  # divide each input by its std\n",
        "#     zca_whitening=False,  # apply ZCA whitening\n",
        "#     rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#     width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "#     height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "#     horizontal_flip=True,  # randomly flip images\n",
        "#     vertical_flip=False,\n",
        "#     zoom_range=0.1,\n",
        "#     channel_shift_range=0.,\n",
        "#     fill_mode='nearest')\n",
        "  \n",
        "#   datagen.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "#   datagen.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "#   train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\",\n",
        "#                                               y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "#   valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\",\n",
        "#                                               y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "#   print(len(train_generator))\n",
        "#   print(\"making model\")\n",
        "#   if not os.path.isfile(model_file):\n",
        "#     model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "#   else:\n",
        "#     model= load_model(model_file)\n",
        "  \n",
        "#   print(\"compiling\")\n",
        "#   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "#   checkpoint= ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "#   callbacks_list = [checkpoint]\n",
        "    \n",
        "#   step_train=train_generator.n//train_generator.batch_size\n",
        "#   step_valid=valid_generator.n//valid_generator.batch_size\n",
        "#   model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch,\n",
        "#                       validation_data=valid_generator, validation_steps=step_valid, shuffle=True,\n",
        "#                       verbose=verbose, callbacks=callbacks_list)\n",
        "#    #\n",
        "  \n",
        "  \n",
        "#   loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,steps=step_train)\n",
        "#   print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "#   loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,steps=step_valid)\n",
        "#   print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxzeaLRCIIlf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm model.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QENRLRsCkKvE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uusJ6dlIjLzQ",
        "colab_type": "code",
        "outputId": "13f5d6cc-3dc8-457f-ded7-159c8f853e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "p = mp.Process(target=watch_, args=(model_file,5))\n",
        "p.start()\n",
        "evaluate_limps(model=0,epoch=1,batch=32,imagenet=True,freeze_all=False,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 36808 images belonging to 2 classes.\n",
            "Found 3197 images belonging to 2 classes.\n",
            "1151\n",
            "making model\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 2s 0us/step\n",
            "compiling\n",
            "Epoch 1/1\n",
            "1150/1150 [==============================] - 1488s 1s/step - loss: 0.6316 - acc: 0.6550 - val_loss: 0.9110 - val_acc: 0.6146\n",
            "\n",
            "Epoch 00001: saving model to model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_6KKtRDLZX5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = mp.Process(target=watch_, args=(model_file,5))\n",
        "p.start()\n",
        "#BUG : CHOSE ANOTHER MODEL , YET LOADED THE OLD ONE\n",
        "#NOT BUG: i told it so, it always loads the last saved version regradless of the model\n",
        "evaluate_limps(model=0,epoch=3,batch=64,imagenet=True,freeze_all=False,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0HrsxfJyzre9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJs80ZDiHqeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9yXbfdHdy1VC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "p = mp.Process(target=watch_, args=(model_file,5))\n",
        "p.start()\n",
        "#BUG : CHOSE ANOTHER MODEL , YET LOADED THE OLD ONE\n",
        "evaluate_limps(model=0,epoch=3,batch=64,imagenet=True,freeze_all=False,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqGa-bNRB91k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}