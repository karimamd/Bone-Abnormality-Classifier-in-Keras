{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MURA Clean Code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Corv113DVLKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ]
    },
    {
      "metadata": {
        "id": "SmaRONjkdPJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cfvs-0PJVXGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
        "#!unzip MURA-v1.1.zip\n",
        "#!rm MURA-v1.1.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hezUpQAcVLK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "pd.options.display.max_colwidth = 100\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v8YQsTLMVLLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training Data"
      ]
    },
    {
      "metadata": {
        "id": "Rv-cPOIWVLLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**output is list of paths to images and list of corresponding labels**"
      ]
    },
    {
      "metadata": {
        "id": "bM2iET2zh73c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#did this because it gave an error at sample  5307 or near it if took all\n",
        "sample_e=5307\n",
        "sample_s2=5339"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VY2ucFC7j9v3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TODO: handle that unread sample problem**\n",
        "If couldn't handle it then see how many labels are +ve and how are -ve to have intuition about model results , maybe because too many samples of one class and little of other"
      ]
    },
    {
      "metadata": {
        "id": "OdWiO-A3kZwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "M7P2A5N8VLLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make dataframe\n",
        "studies=pd.read_csv('MURA-v1.1/train_labeled_studies.csv', sep=',',header=None)\n",
        "#making a list of paths and a corresponding list of labels\n",
        "#using non vectorized for speed\n",
        "#wrist studies\n",
        "wrist_tr=studies[studies[0].str.contains(\"WRIST\")==True]\n",
        "wrist_tr=np.array(wrist_tr)\n",
        "\n",
        "#making a list of paths and a corresponding list of labels\n",
        "#using non vectorized for speed\n",
        "wrist_paths_tr=[]\n",
        "wrist_labels_tr=[]\n",
        "for i in tqdm( range(wrist_tr.shape[0]) ):\n",
        "    study_path=wrist_tr[i][0]\n",
        "    study_label=wrist_tr[i][1]\n",
        "    study_files = [f for f in listdir(study_path) if isfile(join(study_path, f))]\n",
        "    for image in study_files:\n",
        "        wrist_paths_tr.append(study_path + image)\n",
        "        wrist_labels_tr.append(study_label)\n",
        "\n",
        "wrist_paths_tr=np.array(wrist_paths_tr)\n",
        "wrist_labels_tr=np.array(wrist_labels_tr)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(wrist_paths_tr.shape)\n",
        "print(wrist_labels_tr.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ayvPnCKtVLLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Todo : issue , images after preprocessing look different"
      ]
    },
    {
      "metadata": {
        "id": "73Cx7i6MVLLg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "read images from paths to array of images"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "KGUAPVOQVLLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wrist_images_tr=[]\n",
        "for path in tqdm(wrist_paths_tr[:sample_e]):\n",
        "    wrist=k_im_prep.load_img(path, target_size=(224, 224))\n",
        "    wrist_images_tr.append(np.array(wrist))\n",
        "#new start\n",
        "for path in tqdm(wrist_paths_tr[sample_s2:]):\n",
        "    wrist=k_im_prep.load_img(path, target_size=(224, 224))\n",
        "    wrist_images_tr.append(np.array(wrist))\n",
        "#making it a numpy array instead of python list\n",
        "wrist_images_tr=np.array(wrist_images_tr)\n",
        "\n",
        "#wrist_labels_tr=wrist_labels_tr[:sample_e]\n",
        "print(\"\\n\\n\")\n",
        "print(wrist_images_tr.shape)\n",
        "print(wrist_labels_tr.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5fsan6wzjckm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start=wrist_labels_tr[:sample_e]\n",
        "end=wrist_labels_tr[sample_s2:]\n",
        "wrist_labels_tr=np.hstack([  start, end  ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5By9dr_mK1A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(wrist_images_tr.shape)\n",
        "print(wrist_labels_tr.shape)\n",
        "print(start.shape[0]+end.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "07ltju08VLLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#visualizing random sample after preprocesiing \n",
        "index=999\n",
        "plt.imshow(wrist_images_tr[index])\n",
        "print(wrist_labels_tr[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QTW1CCVVLL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "pohTnYHsVLL7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make dataframe\n",
        "studies=pd.read_csv('MURA-v1.1/valid_labeled_studies.csv', sep=',',header=None)\n",
        "#making a list of paths and a corresponding list of labels\n",
        "#using non vectorized for speed\n",
        "#wrist studies\n",
        "wrist_val=studies[studies[0].str.contains(\"WRIST\")==True]\n",
        "wrist_val=np.array(wrist_val)\n",
        "\n",
        "#making a list of paths and a corresponding list of labels\n",
        "#using non vectorized for speed\n",
        "wrist_paths_val=[]\n",
        "wrist_labels_val=[]\n",
        "for i in tqdm( range(wrist_val.shape[0]) ):\n",
        "    study_path=wrist_val[i][0]\n",
        "    study_label=wrist_val[i][1]\n",
        "    study_files = [f for f in listdir(study_path) if isfile(join(study_path, f))]\n",
        "    for image in study_files:\n",
        "        wrist_paths_val.append(study_path + image)\n",
        "        wrist_labels_val.append(study_label)\n",
        "\n",
        "wrist_paths_val=np.array(wrist_paths_val)\n",
        "wrist_labels_val=np.array(wrist_labels_val)\n",
        "\n",
        "wrist_images_val=[]\n",
        "for path in tqdm(wrist_paths_val):\n",
        "    wrist=k_im_prep.load_img(path, target_size=(224, 224))\n",
        "    wrist_images_val.append(np.array(wrist))\n",
        "\n",
        "wrist_images_val=np.array(wrist_images_val)\n",
        "\n",
        "print(wrist_images_val.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXxsDWr2lyGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#visualizing random sample\n",
        "index=650\n",
        "plt.imshow(wrist_images_val[index])\n",
        "print(\"label= \",wrist_labels_val[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVU4aD-tnCVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data bias : train\n",
        "print(\"0 normal, 1 abnormal\")\n",
        "unique, counts = np.unique(wrist_labels_tr, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "#val\n",
        "unique, counts = np.unique(wrist_labels_val, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1u2CNQ7VLMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "mMST4D272Whd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  #weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  #initializing pretrained model\n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        " \n",
        "  if (freeze_all):\n",
        "    #freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "  # add a global spatial average pooling layer\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  \n",
        "  if(add_denses):\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have 200 classes\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # just feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7EJIFlNW6-SA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True)\n",
        "#m.summary()\n",
        "#Choose adam or RMSprop ?!\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(wrist_images_tr, wrist_labels_tr, epochs=5, validation_data=(wrist_images_val, wrist_labels_val), shuffle=True, verbose=1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5EM1-Kd8-lCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(x=wrist_images_tr, y=wrist_labels_tr, batch_size=128, verbose=1)\n",
        "print(\"train loss\",loss,\"train accuracy\",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3VBhd8q0-qmX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(x=wrist_images_val, y=wrist_labels_val, batch_size=128, verbose=1)\n",
        "print(\"validation loss\",loss,\"validation accuracy\",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_9VVa8XVLMw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Current point: generalizing functions and code cleaning+ seeing early stopping callback**"
      ]
    },
    {
      "metadata": {
        "id": "vt5njgtKmMOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All unsolved problems:\n",
        "* why is it in every epoch the result is the same, all results exactly the same\n",
        "* which layers to freeze and which to train + should I train TL before freezing it ?\n",
        "* data augmentation to generate more data\n",
        "* recording variation in accuracy after every change to get intuition\n",
        "* no matter Mobilenet,densenet, added or removed denses same results !! exact same even fractions\n",
        "* the fear of overfitting over validation set\n",
        "* what does outputted loss represent ? how to read the number ?\n",
        "* Get more training data through solving the reading problem and getting the remaining 4k images\n",
        "* normalization step and its effect on accuracy\n",
        "* should I use 1 or two neurons at output layer ?\n",
        "* binary crossentropy weights\n",
        "* justifying parameter use and discovering useful params\n",
        "* try training with model unfrozen with imagenet and without it\n",
        "* make a function to record and tabulate outputs\n",
        "* could we add precision or recall metric ? change accuracy?\n",
        "* why doesn't it work if removed GlobalAveragePooling line?\n",
        "* see if want to freeze less layers"
      ]
    },
    {
      "metadata": {
        "id": "YX4l8VYbVLM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}