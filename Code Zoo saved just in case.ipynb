{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code still yield black picture problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization from image captioning work\n",
    "def preprocess_input(x):\n",
    "  x /= 255.\n",
    "  x -= 0.5\n",
    "  x *= 2.\n",
    "  return x\n",
    "\n",
    "#preprocessing based on keras documentation and old image captioning model\n",
    "\n",
    "def preprocess(image_path):\n",
    "  img = image.load_img(image_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  return x\n",
    "\n",
    "plt.imshow(preprocess(wrist_paths[0])[0])\n",
    "#print(preprocess(wrist_paths[0]).shape)\n",
    "#images.vstack([images,new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow code trial for image preprocessing and reading\n",
    "import tensorflow as tf\n",
    "imagess = tf.image.decode_png(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\",channels=3)\n",
    "resized_image = tf.image.resize_images(imagess, [224, 224])\n",
    "#resized_image=np.array(resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading and resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images and resizing \n",
    "img = image.load_img(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with no resize\n",
    "images=[]\n",
    "for path in tqdm(wrist_paths[:1000]):\n",
    "    wrist=plt.imread(path)\n",
    "    images.append(wrist)\n",
    "\n",
    "images=np.array(images)\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack images to keras shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean image of array of images for normalization\n",
    "# append (224,224,3) images to z=(n,224,224,3)\n",
    "z=[]\n",
    "z.append(np.array(img))\n",
    "z=np.array(z)\n",
    "print(z.shape)\n",
    "m=np.mean(z,axis=0)\n",
    "print(m.shape)\n",
    "\n",
    "#another way to stack images to z\n",
    "c=np.vstack([x,x])\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels processing for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making labels one hot encoded for \"xpected dense_39 to have 4 dimensions, but got array with shape (500, 1)\" problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array([wrist_labels]))\n",
    "Y=enc.fit_transform(np.array([wrist_labels[:500]]), y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=keras.utils.to_categorical(wrist_labels_tr, num_classes=2)\n",
    "#To make array (n,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write custom keras generator:\n",
    "https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a\n",
    "image captioning:\n",
    "https://colab.research.google.com/drive/1YWGQkDKfMfDvelZnPuWaZatfC7XEEk-h#scrollTo=0IPtsB1noe2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras sequential model\n",
    "https://keras.io/models/sequential/#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_model = Sequential()\n",
    "bone_model.add(MobileNetV2_model)\n",
    "bone_model.add(Dense(512, activation='relu'))\n",
    "bone_model.add(Dense(128, activation='relu'))\n",
    "bone_model.add(Dense(32, activation='relu'))\n",
    "#2 because 2 labels\n",
    "bone_model.add(Dense(2, activation='softmax'))\n",
    "# Compile model\n",
    "bone_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "bone_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Inception fine tuning : keras doc**\n",
    "**Inception code from Keras docs**\n",
    "https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is done after freezing and training first\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(wrist_images_tr, wrist_labels_tr, epochs=5, validation_data=(wrist_images_val, wrist_labels_val), shuffle=True, verbose=1 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
