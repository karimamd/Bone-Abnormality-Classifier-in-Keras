{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code Zoo saved just in case.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "C_hIlx3bvT0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "QiFZ9XQGvT0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code still yield black picture problem"
      ]
    },
    {
      "metadata": {
        "id": "TSD16bePvT0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#normalization from image captioning work\n",
        "def preprocess_input(x):\n",
        "  x /= 255.\n",
        "  x -= 0.5\n",
        "  x *= 2.\n",
        "  return x\n",
        "\n",
        "#preprocessing based on keras documentation and old image captioning model\n",
        "\n",
        "def preprocess(image_path):\n",
        "  img = image.load_img(image_path, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  return x\n",
        "\n",
        "plt.imshow(preprocess(wrist_paths[0])[0])\n",
        "#print(preprocess(wrist_paths[0]).shape)\n",
        "#images.vstack([images,new])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAbNkkATvT0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tensorflow code trial for image preprocessing and reading\n",
        "import tensorflow as tf\n",
        "imagess = tf.image.decode_png(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\",channels=3)\n",
        "resized_image = tf.image.resize_images(imagess, [224, 224])\n",
        "#resized_image=np.array(resized_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PPcyMC0vT0N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "reading and resizing images"
      ]
    },
    {
      "metadata": {
        "id": "fAPBKH-NvT0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reading images and resizing \n",
        "img = image.load_img(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\", target_size=(224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_M6kuAAvT0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#with no resize\n",
        "images=[]\n",
        "for path in tqdm(wrist_paths[:1000]):\n",
        "    wrist=plt.imread(path)\n",
        "    images.append(wrist)\n",
        "\n",
        "images=np.array(images)\n",
        "\n",
        "print(images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8z92jyOvT0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "stack images to keras shape"
      ]
    },
    {
      "metadata": {
        "id": "Bh7AreRdvT0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get mean image of array of images for normalization\n",
        "# append (224,224,3) images to z=(n,224,224,3)\n",
        "z=[]\n",
        "z.append(np.array(img))\n",
        "z=np.array(z)\n",
        "print(z.shape)\n",
        "m=np.mean(z,axis=0)\n",
        "print(m.shape)\n",
        "\n",
        "#another way to stack images to z\n",
        "c=np.vstack([x,x])\n",
        "print(c.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hyDqDA7WvT0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "labels processing for keras"
      ]
    },
    {
      "metadata": {
        "id": "xgMMpy1lvT0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#making labels one hot encoded for \"xpected dense_39 to have 4 dimensions, but got array with shape (500, 1)\" problem\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(np.array([wrist_labels]))\n",
        "Y=enc.fit_transform(np.array([wrist_labels[:500]]), y=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVLKhfuUvT0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=keras.utils.to_categorical(wrist_labels_tr, num_classes=2)\n",
        "#To make array (n,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HW_cfOdvT0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "write custom keras generator:\n",
        "https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a\n",
        "image captioning:\n",
        "https://colab.research.google.com/drive/1YWGQkDKfMfDvelZnPuWaZatfC7XEEk-h#scrollTo=0IPtsB1noe2B"
      ]
    },
    {
      "metadata": {
        "id": "P_P1hSUHvT0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras sequential model\n",
        "https://keras.io/models/sequential/#fit"
      ]
    },
    {
      "metadata": {
        "id": "qyxfyOFUvT0x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bone_model = Sequential()\n",
        "bone_model.add(MobileNetV2_model)\n",
        "bone_model.add(Dense(512, activation='relu'))\n",
        "bone_model.add(Dense(128, activation='relu'))\n",
        "bone_model.add(Dense(32, activation='relu'))\n",
        "#2 because 2 labels\n",
        "bone_model.add(Dense(2, activation='softmax'))\n",
        "# Compile model\n",
        "bone_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "bone_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6im9XDvvT00",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Inception fine tuning : keras doc**\n",
        "**Inception code from Keras docs**\n",
        "https://keras.io/applications/"
      ]
    },
    {
      "metadata": {
        "id": "9y4gGvbQvT02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#this is done after freezing and training first\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy')\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(wrist_images_tr, wrist_labels_tr, epochs=5, validation_data=(wrist_images_val, wrist_labels_val), shuffle=True, verbose=1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y6CnHAouPyUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Old wrist only  evaluation method for data generation purposes**"
      ]
    },
    {
      "metadata": {
        "id": "Mh2fOYcTYUOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model=make_FT_model(base=1, imagenet=True, freeze_all=False, add_denses=True)\n",
        "# #m.summary()\n",
        "# #Choose adam or RMSprop ?!\n",
        "# # compile the model (should be done *after* setting layers to non-trainable)\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # fits the model on batches with real-time data augmentation:\n",
        "# model.fit_generator(datagen.flow(wrist_images_tr, wrist_labels_tr, batch_size=16),\n",
        "#                     steps_per_epoch=len(train_imgs) / 16, epochs=10,use_multiprocessing=True,workers=6)\n",
        "\n",
        "# # model.fit(wrist_images_tr, wrist_labels_tr, epochs=5, validation_data=(wrist_images_val, wrist_labels_val), shuffle=True, verbose=1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSU1J5SyPwe-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=make_FT_model(base=2, imagenet=False, freeze_all=False, add_denses=True)\n",
        "#m.summary()\n",
        "#Choose adam or RMSprop ?!\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "'''\n",
        "IF USING OTHER DATA THAN WRIST CHANGE w_labels to train_labels\n",
        "'''\n",
        "model.fit(train_imgs, w_labels, epochs=5, validation_data=(valid_imgs, valid_labels), shuffle=True, verbose=1 )\n",
        "loss,accuracy=model.evaluate(x=train_imgs, y=w_labels, batch_size=128, verbose=1)\n",
        "print(\"train accuracy before data augmenation\",accuracy)\n",
        "loss,accuracy=model.evaluate(x=valid_imgs, y=valid_labels, batch_size=128, verbose=1)\n",
        "print(\"validation accuracy before data augmenation \",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5biqnyzQV5v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=make_FT_model(base=2, imagenet=False, freeze_all=False, add_denses=True)\n",
        "#m.summary()\n",
        "#Choose adam or RMSprop ?!\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "'''\n",
        "IF USING OTHER DATA THAN WRIST CHANGE w_labels to train_labels\n",
        "'''\n",
        "model.fit(train_imgs, w_labels, epochs=5, validation_data=(valid_imgs, valid_labels), shuffle=True, verbose=1 )\n",
        "loss,accuracy=model.evaluate(x=train_imgs, y=w_labels, batch_size=128, verbose=1)\n",
        "print(\"train accuracy before data augmenation\",accuracy)\n",
        "loss,accuracy=model.evaluate(x=valid_imgs, y=valid_labels, batch_size=128, verbose=1)\n",
        "print(\"validation accuracy before data augmenation \",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}