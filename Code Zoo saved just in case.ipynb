{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code still yield black picture problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization from image captioning work\n",
    "def preprocess_input(x):\n",
    "  x /= 255.\n",
    "  x -= 0.5\n",
    "  x *= 2.\n",
    "  return x\n",
    "\n",
    "#preprocessing based on keras documentation and old image captioning model\n",
    "\n",
    "def preprocess(image_path):\n",
    "  img = image.load_img(image_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  return x\n",
    "\n",
    "plt.imshow(preprocess(wrist_paths[0])[0])\n",
    "#print(preprocess(wrist_paths[0]).shape)\n",
    "#images.vstack([images,new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow code trial for image preprocessing and reading\n",
    "import tensorflow as tf\n",
    "imagess = tf.image.decode_png(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\",channels=3)\n",
    "resized_image = tf.image.resize_images(imagess, [224, 224])\n",
    "#resized_image=np.array(resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading and resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images and resizing \n",
    "img = image.load_img(\"MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with no resize\n",
    "images=[]\n",
    "for path in tqdm(wrist_paths[:1000]):\n",
    "    wrist=plt.imread(path)\n",
    "    images.append(wrist)\n",
    "\n",
    "images=np.array(images)\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack images to keras shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean image of array of images for normalization\n",
    "# append (224,224,3) images to z=(n,224,224,3)\n",
    "z=[]\n",
    "z.append(np.array(img))\n",
    "z=np.array(z)\n",
    "print(z.shape)\n",
    "m=np.mean(z,axis=0)\n",
    "print(m.shape)\n",
    "\n",
    "#another way to stack images to z\n",
    "c=np.vstack([x,x])\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels processing for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making labels one hot encoded for \"xpected dense_39 to have 4 dimensions, but got array with shape (500, 1)\" problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array([wrist_labels]))\n",
    "Y=enc.fit_transform(np.array([wrist_labels[:500]]), y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write custom keras generator:\n",
    "https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a\n",
    "image captioning:\n",
    "https://colab.research.google.com/drive/1YWGQkDKfMfDvelZnPuWaZatfC7XEEk-h#scrollTo=0IPtsB1noe2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras sequential model\n",
    "https://keras.io/models/sequential/#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_model = Sequential()\n",
    "bone_model.add(MobileNetV2_model)\n",
    "bone_model.add(Dense(512, activation='relu'))\n",
    "bone_model.add(Dense(128, activation='relu'))\n",
    "bone_model.add(Dense(32, activation='relu'))\n",
    "#2 because 2 labels\n",
    "bone_model.add(Dense(2, activation='softmax'))\n",
    "# Compile model\n",
    "bone_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "bone_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
