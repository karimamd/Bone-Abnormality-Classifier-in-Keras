{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Ready_Feature_conct.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "N790OUoYiuDG",
        "vbXWb8jCVsGx",
        "2Atw91wISar9",
        "77y48PtKSdLz",
        "ljRpA2shuet1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimamd/Bone-Abnormality-Classifier-in-Keras/blob/Khaled-Branch/Ensemble_Ready_Feature_conct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "up1iA_3xOwax",
        "colab_type": "code",
        "outputId": "8803dbd6-b427-4701-a0d9-11dcf56152aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-18 14:41:10--  https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380245855 (3.1G) [application/zip]\n",
            "Saving to: ‘MURA-v1.1.zip’\n",
            "\n",
            "MURA-v1.1.zip         2%[                    ]  80.01M  9.14MB/s    eta 4m 52s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c1q30MNoZrZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import zipfile\n",
        "import time\n",
        "import concurrent.futures\n",
        "\n",
        "# timer func evaluates func/s running time in minutes\n",
        "def timer(f):\n",
        "\n",
        "    def inner(*args, **kwargs):\n",
        "        try:\n",
        "            t0 = time.time()\n",
        "            return f(*args, **kwargs)\n",
        "        finally:\n",
        "            t1 = time.time()\n",
        "            print(f.__name__, 'executed in', (t1 - t0) / 60, ' min/s')\n",
        "\n",
        "    return inner\n",
        "\n",
        "# fast unzip, usually 900% faster than normal \"unzip\" command\n",
        "# thanks to Peter Bengtsson <3: https://www.peterbe.com/\n",
        "\n",
        "@timer\n",
        "def fast_unzip(fn, dest):\n",
        "\n",
        "    def unzip_member(zf, name, dest):\n",
        "        while True:\n",
        "            try:\n",
        "                zf.extract(name, dest)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                if e.errno != os.errno.EEXIST:\n",
        "                    raise\n",
        "                time.sleep(2)\n",
        "                pass\n",
        "\n",
        "    with open(fn, 'rb') as f:\n",
        "        zf = zipfile.ZipFile(f)\n",
        "        futures = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            for member in zf.infolist():\n",
        "                futures.append(executor.submit(unzip_member, zf,\n",
        "                               member.filename, dest))\n",
        "\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-JgkBnialez",
        "colab_type": "code",
        "outputId": "4fb54a15-36c1-4f8c-90d1-a65205fd1794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fast_unzip('MURA-v1.1.zip','/content')\n",
        "!rm MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fast_unzip executed in 0.8564196546872457  min/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DMY_KstJs079",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall keras -y\n",
        "!pip3 install git+https://github.com/keras-team/keras\n",
        "!pip uninstall keras-preprocessing -y\n",
        "!pip3 install git+https://github.com/keras-team/keras-preprocessing\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rdHciFEs2Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to force restart runtime\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9)\n",
        "  \n",
        "try:\n",
        "    restart_runtime\n",
        "except NameError:\n",
        "    print(\"already restarted!\")\n",
        "else:\n",
        "    restart_runtime()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_91u16WOSr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, signal, shutil\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input,Flatten\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras import backend as K\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Elt6blzj0a3",
        "colab_type": "code",
        "outputId": "8b6cf5fc-0896-4817-84bd-573c037994bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total_size = 0\n",
        "# to get size of certain directory\n",
        "for path, dirs, files in os.walk('MURA-v1.1'):\n",
        "    for f in files:\n",
        "        fp = os.path.join(path, f)\n",
        "        total_size += os.path.getsize(fp)\n",
        "print(\"Directory size: \" + str(total_size/1024**3) + \" (Gigabyte)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory size: 3.1397332791239023 (Gigabyte)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ez9S9xLB0yIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# onlyfiles = [f for f in listdir(\"MURA-v1.1\")]\n",
        "# print(onlyfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgFz9AwaBzBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Directory of saved models { form-width: \"30%\", display-mode: \"both\" }\n",
        "\n",
        "''' select \"unique name\" for \"your\" models directory where pre-trained/saved\n",
        "models will be uploaded to Dropbox if you want to apply any modifications \n",
        "such as preprocessing '''\n",
        "\n",
        "dir = \"khalodmodels\" #@param {type:\"string\"}\n",
        "dir = dir + \"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N790OUoYiuDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SETUP \n",
        "### just run all cells in this section"
      ]
    },
    {
      "metadata": {
        "id": "_FjBSeR09-UZ",
        "colab_type": "code",
        "outputId": "505d255c-899b-490a-aac7-82c87dcccaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "# just run the cell to be able to upload and download from Dropbox\n",
        "!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
        "!chmod +x Dropbox-Uploader/dropbox_uploader.sh\n",
        "source = 'Dropbox-Uploader'\n",
        "dest1 = '/content'\n",
        "shutil.move(source+'/'+'dropbox_uploader.sh', dest1)\n",
        "!echo \"pzFqTa1uWVAAAAAAAAAACtGcVohdBzoFRrwtLYsQCxhD9a7IjevvuOTNV8OWB2LX\" > token.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Dropbox-Uploader' already exists and is not an empty directory.\n",
            "chmod: cannot access 'Dropbox-Uploader/dropbox_uploader.sh': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-75ae0ecd3cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Dropbox-Uploader'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'dropbox_uploader.sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo \"pzFqTa1uWVAAAAAAAAAACtGcVohdBzoFRrwtLYsQCxhD9a7IjevvuOTNV8OWB2LX\" > token.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mreal_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Destination path '/content/dropbox_uploader.sh' already exists"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cTqlisSN_xe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh download README.md > log.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBG6GG75QHwc",
        "colab_type": "code",
        "outputId": "3347fe9e-ebe6-416e-fa7d-c063c740d289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# download train and valid csv files that include images path and their labels\n",
        "!bash dropbox_uploader.sh -p download /labels_csv/train_paths_labels.csv\n",
        "!bash dropbox_uploader.sh -p download /labels_csv/valid_paths_labels.csv\n",
        "\n",
        "# create folder of pre-trained/saved models if it doesn't exist\n",
        "os.system(\"bash dropbox_uploader.sh mkdir /\"+ dir[:-1] +\" > log.txt\")\n",
        "\n",
        "# download folder of pre-trained/saved models\n",
        "os.system(\"bash dropbox_uploader.sh download \"+ dir[:-1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Skipping file \"/labels_csv/train_paths_labels.csv\", file exists with the same hash\n",
            "> Skipping file \"/labels_csv/valid_paths_labels.csv\", file exists with the same hash\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "6Cu15H_TCAVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# watch_ monitors the state of certain file if it is modified and uploads it to Dropbox if so\n",
        "def watch_(file, interval):\n",
        "    first_Time = False\n",
        "    while True:\n",
        "        if os.path.isfile(dir + file):\n",
        "            if not first_Time:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "                first_Time = True\n",
        "                \n",
        "            moddate = os.stat(dir + file)[8]\n",
        "            time.sleep(interval)\n",
        "            moddate_ = os.stat(dir + file)[8]\n",
        "            \n",
        "            if moddate < moddate_:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "        else:\n",
        "            time.sleep(interval)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lckhF_XQeLN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbXWb8jCVsGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ]
    },
    {
      "metadata": {
        "id": "4Y4fjRr9Vwl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  #weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  #default because refrenced before assignment error, just scroll down\n",
        "  base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "\n",
        "#   feature_Concatenation_Merged=None\n",
        "  #initializing pretrained model\n",
        "  \n",
        "  print(\"Choose model is\",base)\n",
        "  \n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 3):\n",
        "    base_model = ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False)   \n",
        "  elif (base == 4):\n",
        "    base_model = NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 6): #Feature concatenated\n",
        "    base_model_new = Input(shape= (224, 224, 3))  \n",
        " \n",
        "  if (freeze_all):\n",
        "    #freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "\n",
        "\n",
        "  if(add_denses):\n",
        "    \n",
        "\n",
        "    if(base ==6):  #Feature concatenated\n",
        "      \n",
        "      print(\"Adding bases\")\n",
        "      feature_Concatenation_model1=NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False, input_tensor=base_model_new)\n",
        "      feature_Concatenation_model2=MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False, input_tensor=base_model_new)\n",
        "\n",
        "      x1 = feature_Concatenation_model1.output\n",
        "      x1 = GlobalAveragePooling2D()(x1)\n",
        "   \n",
        "      x2 = feature_Concatenation_model2.output\n",
        "      x2 = GlobalAveragePooling2D()(x2)\n",
        "      \n",
        "\n",
        " \n",
        "\n",
        "      merge = concatenate([x1, x2])\n",
        "      \n",
        "      \n",
        "      merge = Dense(512, activation='relu')(merge)\n",
        "      merge = Dense(128, activation='relu')(merge)\n",
        "      \n",
        "      predictions = Dense(1, activation='sigmoid')(merge)\n",
        "      \n",
        "      print(\"Model Creation\")\n",
        "\n",
        "      feature_Concatenation_Merged = Model(inputs=[base_model_new],outputs=predictions)\n",
        "      model= feature_Concatenation_Merged\n",
        "      print(\"all here done\")\n",
        "\n",
        "      \n",
        "    else:\n",
        "            \n",
        "      # add a global spatial average pooling layer\n",
        "      x = base_model.output\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      \n",
        "      # let's add a fully-connected layer\n",
        "      #x = Dense(1024, activation='relu')(x)\n",
        "      x = Dense(512, activation='relu')(x)\n",
        "      x = Dense(128, activation='relu')(x)\n",
        "      #x = Dense(32, activation='relu')(x)\n",
        "      # and a logistic layer -- let's say we have 200 classes\n",
        "\n",
        "      predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "      # this is the model we will train\n",
        "      model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # just feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  plot_model(model,to_file='demo.png',show_shapes=True)\n",
        "#   SVG(model_to_dot(model).create(prog='’'dot’, format=’svg’))\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzAiJSX0TX-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_names=['MobileNetV2','DenseNet169','InceptionV3','ResNet50','NASNetMobile','Xception','Feature_Conct']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1FlPKw5LXEOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# @timer\n",
        "# def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "  \n",
        "#   model_file= 'model_'+models_names[model]+'.h5'\n",
        "  \n",
        "#   df_train=pd.read_csv('train_paths_labels.csv')\n",
        "#   df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "#   datagen=ImageDataGenerator(rescale=1./255)\n",
        "#   train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "#   valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  \n",
        "#   keras.backend.clear_session()\n",
        "  \n",
        "  \n",
        "#   if not os.path.isfile(dir+model_file):\n",
        "#     print(\"making model\")\n",
        "#     model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "#   else:\n",
        "#     print(\"loading saved model\")\n",
        "#     model= load_model(dir+model_file)\n",
        "  \n",
        "#   print(\"compiling\")\n",
        "#   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "#   checkpoint= ModelCheckpoint(dir+model_file, monitor='val_loss', verbose=1, save_best_only=False,\n",
        "#                               save_weights_only=False, mode='auto', period=1)\n",
        "#   callbacks_list = [checkpoint]\n",
        "    \n",
        "#   step_train=train_generator.n//train_generator.batch_size\n",
        "#   step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  \n",
        "#   model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch, validation_data=valid_generator,\n",
        "#                       validation_steps=step_valid, shuffle=True, verbose=verbose, callbacks=callbacks_list)\n",
        "  \n",
        "  \n",
        "  \n",
        "#   loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,workers=5,steps=step_train)\n",
        "#   print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "#   loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,workers=5,steps=step_valid)\n",
        "#   print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Atw91wISar9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kareem's eval function"
      ]
    },
    {
      "metadata": {
        "id": "bEX9fTsAO5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#KAREEM'S COPY OF FUNCTION JUST COMMENT THE CELL AND EVERYTHING IS NORMAL\n",
        "def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv')\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "  datagen = ImageDataGenerator(  rescale=1./255,\n",
        "    featurewise_center=True,  #CHANGED IT TO TRUE # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=True,  #CHANGED IT TO TRUE# divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.1,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode='nearest')\n",
        "  \n",
        "  datagen.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  datagen.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  print(len(train_generator))\n",
        "  print(\"making model\")\n",
        "  if not os.path.isfile(model_file):\n",
        "    model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "  else:\n",
        "    model= load_model(model_file, compile=False)\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch,\n",
        "                      validation_data=valid_generator, validation_steps=step_valid, shuffle=True,\n",
        "                      verbose=verbose, callbacks=callbacks_list)\n",
        "   #Confession matrix part\n",
        "   ###########################################\n",
        "  \n",
        "  num_of_test_samples=3197\n",
        "  \n",
        "  Y_pred = model.predict_generator(valid_generator, num_of_test_samples // batch_size+1)\n",
        "  y_pred = np.argmax(Y_pred, axis=1)\n",
        "  print('Confusion Matrix')\n",
        "  print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "  print('Classification Report')\n",
        "  target_names = ['Normal', 'Abnormal']\n",
        "  print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
        "  \n",
        "  \n",
        "#   y_pred=model.predict(valid_imgs)\n",
        "  y_pred[y_pred >=0.5]=1\n",
        "  y_pred[y_pred <0.5]=0\n",
        "\n",
        "\n",
        "  y_pred_for_training=model.predict(train_imgs)\n",
        "  y_pred_for_training[y_pred_for_training >=0.5]=1\n",
        "  y_pred_for_training[y_pred_for_training < 0.5]=0\n",
        "\n",
        "\n",
        "  print(\"second prediction vlayes\")\n",
        "  print(y_pred)\n",
        "\n",
        "  # Compute confusion matrix\n",
        "  cnf_matrix = confusion_matrix(valid_labels, y_pred)\n",
        "\n",
        "  cnf_matrix2 = confusion_matrix(train_labels, y_pred_for_training)\n",
        "  \n",
        "  plot_matrix_multiples(cnf_matrix,Name='Confusion matrix for valiadation set')\n",
        "  \n",
        "  plot_matrix_multiples(cnf_matrix2,Name='Confusion matrix for training set')\n",
        "\n",
        "  \n",
        "    \n",
        "  ###########################################\n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,steps=step_train)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,steps=step_valid)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iicD-VGd9oQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ad390e6-38dd-4f7f-9ffb-ea2a9ca5d90b"
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh upload model_Feature_Conct.h5 khalodmodels/model_Feature_Conct.h5"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Uploading \"/content/model_Feature_Conct.h5\" to \"/khalodmodels/model_Feature_Conct.h5\"... DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KEcCuFNP0TAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_matrix_multiples(cnf_matrix,Name):\n",
        "  \n",
        "  np.set_printoptions(precision=2)\n",
        "\n",
        "  cm_class_label = ['Normal','abnormal']\n",
        "  # Plot non-normalized confusion matrix\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(cnf_matrix,cm_class_label,title=Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77y48PtKSdLz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SubModel/s Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "QENRLRsCkKvE",
        "colab_type": "code",
        "outputId": "21b58271-ca29-45af-d6ca-4eb9c3898403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dropbox-Uploader     log.txt\tMURA-v1.1.zip  train_paths_labels.csv\n",
            "dropbox_uploader.sh  models\tREADME.md      valid_paths_labels.csv\n",
            "khalodmodels\t     MURA-v1.1\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uusJ6dlIjLzQ",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "182a6b60-9345-4f7a-e683-a6babef362af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SubModel Evaluation { form-width: \"30%\" }\n",
        "model = 6 #@param {type:\"number\"}\n",
        "epoch = 1 #@param {type:\"integer\"}\n",
        "batch_size = 32 #@param {type:\"integer\"}\n",
        "\n",
        "# No need now as I saved submodels and using them in ensemble model\n",
        "\n",
        "model_file= 'model_'+ models_names[model] +'.h5'\n",
        "\n",
        "p = mp.Process(target=watch_, args=(model_file,20))\n",
        "p.start()\n",
        "evaluate_limps(model=model,epoch=epoch,batch=batch_size,imagenet=True,freeze_all=False,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 36808 images belonging to 2 classes.\n",
            "Found 3197 images belonging to 2 classes.\n",
            "1151\n",
            "making model\n",
            "compiling\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljRpA2shuet1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble Model\n",
        "### MobileNetV2 + DenseNet + Resnet50 (pretrained + downloaded from Dropbox)"
      ]
    },
    {
      "metadata": {
        "id": "eB7Q0lcYuXQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all_models = list()\n",
        "# for i in listdir(dir):\n",
        " \n",
        "#   if i == 'model_NASNetMobile.h5' or i == 'model_ensemble.h5':\n",
        "#     continue\n",
        "    \n",
        "#   filename = dir + i\n",
        "#   # load model from file\n",
        "#   model = load_model(filename)\n",
        "#   # add to list of members\n",
        "#   all_models.append(model)\n",
        "#   print('loaded ',filename)\n",
        "\n",
        "# def ensemble_model(all_models):\n",
        "  \n",
        "#   for i in range(len(all_models)):\n",
        "#     model = all_models[i]\n",
        "#     for layer in model.layers:\n",
        "#       # make not trainable\n",
        "#       layer.trainable = False\n",
        "#       # rename to avoid 'unique layer name' issue\n",
        "#       layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        "#   # define multi-headed input\n",
        "#   ensemble_visible = [model.input for model in all_models]\n",
        "#   # concatenate merge output from each model\n",
        "#   ensemble_outputs = [model.output for model in all_models]\n",
        "#   merge = concatenate(ensemble_outputs)\n",
        "#   #print(merge.shape)\n",
        "#   #merge = keras.layers.Permute((2,1))(merge)\n",
        "#   #merge=keras.layers.Reshape((3,),dtype=tf.float32_ref)(merge)\n",
        "#   hidden = Dense(128, activation='relu')(merge)\n",
        "#   output = Dense(1, activation='sigmoid')(hidden)\n",
        "#   model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  \n",
        "#   # plot graph of ensemble\n",
        "#   plot_model(model, show_shapes=True, to_file='ensemble_model_graph.png')\n",
        "#   # compile\n",
        "#   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zj5DONfhEhmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# @timer\n",
        "# def eval_ensemble(model_file='model_ensemble.h5',epoch=3,batch=64,verbose=2):\n",
        "  \n",
        "  \n",
        "#   df_train=pd.read_csv('train_paths_labels.csv')\n",
        "#   df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "#   datagen=ImageDataGenerator(rescale=1./255)\n",
        "#   train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\",\n",
        "#                                               target_size=(224,224), batch_size=batch)\n",
        "#   valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\",\n",
        "#                                               target_size=(224,224), batch_size=batch)\n",
        "  \n",
        "#   keras.backend.clear_session()\n",
        "  \n",
        "  \n",
        "#   if not os.path.isfile(dir + model_file):\n",
        "#     print(\"making ensemble model\")\n",
        "#     model = ensemble_model(all_models)\n",
        "#   else:\n",
        "#     print(\"loading saved ensemble model\")\n",
        "#     model= load_model(dir + model_file)\n",
        "  \n",
        "#   print(\"compiling\")\n",
        "#   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "#   checkpoint= ModelCheckpoint(dir + model_file, monitor='val_loss', verbose=1, save_best_only=False,\n",
        "#                               save_weights_only=False, mode='auto', period=1)\n",
        "#   callbacks_list = [checkpoint]\n",
        "    \n",
        "#   step_train=train_generator.n//train_generator.batch_size\n",
        "#   step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  \n",
        "#   model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch, validation_data=valid_generator,\n",
        "#                       validation_steps=step_valid, shuffle=True, verbose=verbose, callbacks=callbacks_list)\n",
        "  \n",
        "  \n",
        "  \n",
        "#   loss_tr, accuracy_tr = model.evaluate_generator(train_generator, use_multiprocessing=True,workers=5,steps=step_train)\n",
        "#   print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "#   loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,workers=5,steps=step_valid)\n",
        "#   print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nYYbTcHGI42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #@title SubModel Evaluation { form-width: \"30%\" }\n",
        "# epoch = 3 #@param {type:\"integer\"}\n",
        "# batch_size = 64 #@param {type:\"integer\"}\n",
        "\n",
        "# model_file= 'model_ensemble.h5'\n",
        "\n",
        "# p = mp.Process(target=watch_, args=(model_file,20))\n",
        "# p.start()\n",
        "# eval_ensemble(model_file=model_file,epoch=3,batch=batch_size,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6h24yRz4_rts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}