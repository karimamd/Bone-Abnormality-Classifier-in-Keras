{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "N790OUoYiuDG",
        "vbXWb8jCVsGx",
        "2Atw91wISar9",
        "77y48PtKSdLz",
        "ljRpA2shuet1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimamd/Bone-Abnormality-Classifier-in-Keras/blob/Khaled-Branch/Ensemble_Ready_Feature_conct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "up1iA_3xOwax",
        "colab_type": "code",
        "outputId": "a2269bfe-d091-4224-a71e-aa899c2d9e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-18 12:38:59--  https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380245855 (3.1G) [application/zip]\n",
            "Saving to: ‘MURA-v1.1.zip’\n",
            "\n",
            "MURA-v1.1.zip       100%[===================>]   3.15G  14.2MB/s    in 3m 54s  \n",
            "\n",
            "2019-01-18 12:42:59 (13.8 MB/s) - ‘MURA-v1.1.zip’ saved [3380245855/3380245855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c1q30MNoZrZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import zipfile\n",
        "import time\n",
        "import concurrent.futures\n",
        "\n",
        "# timer func evaluates func/s running time in minutes\n",
        "def timer(f):\n",
        "\n",
        "    def inner(*args, **kwargs):\n",
        "        try:\n",
        "            t0 = time.time()\n",
        "            return f(*args, **kwargs)\n",
        "        finally:\n",
        "            t1 = time.time()\n",
        "            print(f.__name__, 'executed in', (t1 - t0) / 60, ' min/s')\n",
        "\n",
        "    return inner\n",
        "\n",
        "# fast unzip, usually 900% faster than normal \"unzip\" command\n",
        "# thanks to Peter Bengtsson <3: https://www.peterbe.com/\n",
        "\n",
        "@timer\n",
        "def fast_unzip(fn, dest):\n",
        "\n",
        "    def unzip_member(zf, name, dest):\n",
        "        while True:\n",
        "            try:\n",
        "                zf.extract(name, dest)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                if e.errno != os.errno.EEXIST:\n",
        "                    raise\n",
        "                time.sleep(2)\n",
        "                pass\n",
        "\n",
        "    with open(fn, 'rb') as f:\n",
        "        zf = zipfile.ZipFile(f)\n",
        "        futures = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            for member in zf.infolist():\n",
        "                futures.append(executor.submit(unzip_member, zf,\n",
        "                               member.filename, dest))\n",
        "\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-JgkBnialez",
        "colab_type": "code",
        "outputId": "4fb54a15-36c1-4f8c-90d1-a65205fd1794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fast_unzip('MURA-v1.1.zip','/content')\n",
        "!rm MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fast_unzip executed in 0.8564196546872457  min/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DMY_KstJs079",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall keras -y\n",
        "!pip3 install git+https://github.com/keras-team/keras\n",
        "!pip uninstall keras-preprocessing -y\n",
        "!pip3 install git+https://github.com/keras-team/keras-preprocessing\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rdHciFEs2Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to force restart runtime\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9)\n",
        "  \n",
        "try:\n",
        "    restart_runtime\n",
        "except NameError:\n",
        "    print(\"already restarted!\")\n",
        "else:\n",
        "    restart_runtime()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_91u16WOSr3",
        "colab_type": "code",
        "outputId": "565109fa-2cb9-4f0b-e534-212fa18d5f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, signal, shutil\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras import backend as K\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Elt6blzj0a3",
        "colab_type": "code",
        "outputId": "0c165afe-2968-4fcc-b57d-0c7e27466cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total_size = 0\n",
        "# to get size of certain directory\n",
        "for path, dirs, files in os.walk('MURA-v1.1'):\n",
        "    for f in files:\n",
        "        fp = os.path.join(path, f)\n",
        "        total_size += os.path.getsize(fp)\n",
        "print(\"Directory size: \" + str(total_size/1024**3) + \" (Gigabyte)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory size: 3.1397332791239023 (Gigabyte)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ez9S9xLB0yIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# onlyfiles = [f for f in listdir(\"MURA-v1.1\")]\n",
        "# print(onlyfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgFz9AwaBzBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Directory of saved models { form-width: \"30%\", display-mode: \"both\" }\n",
        "\n",
        "''' select \"unique name\" for \"your\" models directory where pre-trained/saved\n",
        "models will be uploaded to Dropbox if you want to apply any modifications \n",
        "such as preprocessing '''\n",
        "\n",
        "dir = \"models\" #@param {type:\"string\"}\n",
        "dir = dir + \"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N790OUoYiuDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SETUP \n",
        "### just run all cells in this section"
      ]
    },
    {
      "metadata": {
        "id": "_FjBSeR09-UZ",
        "colab_type": "code",
        "outputId": "17944ca6-1854-40e3-b7ae-0a45a322f21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "# just run the cell to be able to upload and download from Dropbox\n",
        "!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
        "!chmod +x Dropbox-Uploader/dropbox_uploader.sh\n",
        "source = 'Dropbox-Uploader'\n",
        "dest1 = '/content'\n",
        "shutil.move(source+'/'+'dropbox_uploader.sh', dest1)\n",
        "!echo \"pzFqTa1uWVAAAAAAAAAACtGcVohdBzoFRrwtLYsQCxhD9a7IjevvuOTNV8OWB2LX\" > token.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dropbox-Uploader'...\n",
            "remote: Enumerating objects: 951, done.\u001b[K\n",
            "Receiving objects:   0% (1/951)   \rReceiving objects:   1% (10/951)   \rReceiving objects:   2% (20/951)   \rReceiving objects:   3% (29/951)   \rReceiving objects:   4% (39/951)   \rReceiving objects:   5% (48/951)   \rReceiving objects:   6% (58/951)   \rReceiving objects:   7% (67/951)   \rReceiving objects:   8% (77/951)   \rReceiving objects:   9% (86/951)   \rReceiving objects:  10% (96/951)   \rReceiving objects:  11% (105/951)   \rReceiving objects:  12% (115/951)   \rReceiving objects:  13% (124/951)   \rReceiving objects:  14% (134/951)   \rReceiving objects:  15% (143/951)   \rReceiving objects:  16% (153/951)   \rReceiving objects:  17% (162/951)   \rReceiving objects:  18% (172/951)   \rReceiving objects:  19% (181/951)   \rReceiving objects:  20% (191/951)   \rReceiving objects:  21% (200/951)   \rReceiving objects:  22% (210/951)   \rReceiving objects:  23% (219/951)   \rReceiving objects:  24% (229/951)   \rReceiving objects:  25% (238/951)   \rReceiving objects:  26% (248/951)   \rReceiving objects:  27% (257/951)   \rReceiving objects:  28% (267/951)   \rReceiving objects:  29% (276/951)   \rReceiving objects:  30% (286/951)   \rReceiving objects:  31% (295/951)   \rReceiving objects:  32% (305/951)   \rReceiving objects:  33% (314/951)   \rReceiving objects:  34% (324/951)   \rReceiving objects:  35% (333/951)   \rReceiving objects:  36% (343/951)   \rReceiving objects:  37% (352/951)   \rReceiving objects:  38% (362/951)   \rReceiving objects:  39% (371/951)   \rReceiving objects:  40% (381/951)   \rReceiving objects:  41% (390/951)   \rReceiving objects:  42% (400/951)   \rReceiving objects:  43% (409/951)   \rReceiving objects:  44% (419/951)   \rReceiving objects:  45% (428/951)   \rReceiving objects:  46% (438/951)   \rReceiving objects:  47% (447/951)   \rReceiving objects:  48% (457/951)   \rReceiving objects:  49% (466/951)   \rReceiving objects:  50% (476/951)   \rReceiving objects:  51% (486/951)   \rReceiving objects:  52% (495/951)   \rReceiving objects:  53% (505/951)   \rReceiving objects:  54% (514/951)   \rReceiving objects:  55% (524/951)   \rReceiving objects:  56% (533/951)   \rReceiving objects:  57% (543/951)   \rReceiving objects:  58% (552/951)   \rReceiving objects:  59% (562/951)   \rReceiving objects:  60% (571/951)   \rReceiving objects:  61% (581/951)   \rReceiving objects:  62% (590/951)   \rReceiving objects:  63% (600/951)   \rReceiving objects:  64% (609/951)   \rReceiving objects:  65% (619/951)   \rReceiving objects:  66% (628/951)   \rReceiving objects:  67% (638/951)   \rReceiving objects:  68% (647/951)   \rReceiving objects:  69% (657/951)   \rReceiving objects:  70% (666/951)   \rReceiving objects:  71% (676/951)   \rReceiving objects:  72% (685/951)   \rReceiving objects:  73% (695/951)   \rReceiving objects:  74% (704/951)   \rReceiving objects:  75% (714/951)   \rReceiving objects:  76% (723/951)   \rReceiving objects:  77% (733/951)   \rReceiving objects:  78% (742/951)   \rremote: Total 951 (delta 0), reused 0 (delta 0), pack-reused 951\u001b[K\n",
            "Receiving objects:  79% (752/951)   \rReceiving objects:  80% (761/951)   \rReceiving objects:  81% (771/951)   \rReceiving objects:  82% (780/951)   \rReceiving objects:  83% (790/951)   \rReceiving objects:  84% (799/951)   \rReceiving objects:  85% (809/951)   \rReceiving objects:  86% (818/951)   \rReceiving objects:  87% (828/951)   \rReceiving objects:  88% (837/951)   \rReceiving objects:  89% (847/951)   \rReceiving objects:  90% (856/951)   \rReceiving objects:  91% (866/951)   \rReceiving objects:  92% (875/951)   \rReceiving objects:  93% (885/951)   \rReceiving objects:  94% (894/951)   \rReceiving objects:  95% (904/951)   \rReceiving objects:  96% (913/951)   \rReceiving objects:  97% (923/951)   \rReceiving objects:  98% (932/951)   \rReceiving objects:  99% (942/951)   \rReceiving objects: 100% (951/951)   \rReceiving objects: 100% (951/951), 318.69 KiB | 1.10 MiB/s, done.\n",
            "Resolving deltas:   0% (0/506)   \rResolving deltas:   5% (26/506)   \rResolving deltas:   9% (47/506)   \rResolving deltas:  11% (58/506)   \rResolving deltas:  19% (100/506)   \rResolving deltas:  38% (195/506)   \rResolving deltas:  46% (233/506)   \rResolving deltas:  50% (258/506)   \rResolving deltas:  52% (265/506)   \rResolving deltas:  58% (298/506)   \rResolving deltas:  62% (317/506)   \rResolving deltas:  64% (326/506)   \rResolving deltas:  66% (338/506)   \rResolving deltas:  68% (345/506)   \rResolving deltas:  69% (351/506)   \rResolving deltas:  75% (380/506)   \rResolving deltas:  79% (402/506)   \rResolving deltas:  80% (406/506)   \rResolving deltas:  81% (411/506)   \rResolving deltas:  82% (417/506)   \rResolving deltas:  83% (424/506)   \rResolving deltas:  84% (426/506)   \rResolving deltas:  85% (433/506)   \rResolving deltas:  89% (452/506)   \rResolving deltas:  92% (467/506)   \rResolving deltas: 100% (506/506)   \rResolving deltas: 100% (506/506), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cTqlisSN_xe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh download README.md > log.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBG6GG75QHwc",
        "colab_type": "code",
        "outputId": "f823d34a-dafd-432d-8cd5-ccaab5b9c142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# download train and valid csv files that include images path and their labels\n",
        "!bash dropbox_uploader.sh -p download /labels_csv/train_paths_labels.csv\n",
        "!bash dropbox_uploader.sh -p download /labels_csv/valid_paths_labels.csv\n",
        "\n",
        "# create folder of pre-trained/saved models if it doesn't exist\n",
        "os.system(\"bash dropbox_uploader.sh mkdir /\"+ dir[:-1] +\" > log.txt\")\n",
        "\n",
        "# download folder of pre-trained/saved models\n",
        "os.system(\"bash dropbox_uploader.sh download \"+ dir[:-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Downloading \"/labels_csv/train_paths_labels.csv\" to \"/content/train_paths_labels.csv\"... \n",
            "######################################################################## 100.0%\n",
            "DONE\n",
            " > Downloading \"/labels_csv/valid_paths_labels.csv\" to \"/content/valid_paths_labels.csv\"... \n",
            "######################################################################## 100.0%\n",
            "DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6Cu15H_TCAVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# watch_ monitors the state of certain file if it is modified and uploads it to Dropbox if so\n",
        "def watch_(file, interval):\n",
        "    first_Time = False\n",
        "    while True:\n",
        "        if os.path.isfile(dir + file):\n",
        "            if not first_Time:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "                first_Time = True\n",
        "                \n",
        "            moddate = os.stat(dir + file)[8]\n",
        "            time.sleep(interval)\n",
        "            moddate_ = os.stat(dir + file)[8]\n",
        "            \n",
        "            if moddate < moddate_:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "        else:\n",
        "            time.sleep(interval)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbXWb8jCVsGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ]
    },
    {
      "metadata": {
        "id": "4Y4fjRr9Vwl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  # weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  # default because refrenced before assignment error, just scroll down\n",
        "  base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  \n",
        "  # initializing pretrained model\n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 3):\n",
        "    base_model = ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False)   \n",
        "  elif (base == 4):\n",
        "    base_model = NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 5):\n",
        "    base_model = Xception(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        " \n",
        "  if (freeze_all):\n",
        "    # freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "  # add a global spatial average pooling layer\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  \n",
        "  if(add_denses):\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    # target model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzAiJSX0TX-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_names=['MobileNetV2','DenseNet169','InceptionV3','ResNet50','NASNetMobile','Xception']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1FlPKw5LXEOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "@timer\n",
        "def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "  \n",
        "  model_file= 'model_'+models_names[model]+'.h5'\n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv')\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "  datagen=ImageDataGenerator(rescale=1./255)\n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  \n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  \n",
        "  if not os.path.isfile(dir+model_file):\n",
        "    print(\"making model\")\n",
        "    model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "  else:\n",
        "    print(\"loading saved model\")\n",
        "    model= load_model(dir+model_file)\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(dir+model_file, monitor='val_loss', verbose=1, save_best_only=False,\n",
        "                              save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  \n",
        "  model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch, validation_data=valid_generator,\n",
        "                      validation_steps=step_valid, shuffle=True, verbose=verbose, callbacks=callbacks_list)\n",
        "  \n",
        "  \n",
        "  \n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,workers=5,steps=step_train)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,workers=5,steps=step_valid)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Atw91wISar9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kareem's eval function"
      ]
    },
    {
      "metadata": {
        "id": "bEX9fTsAO5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #KAREEM'S COPY OF FUNCTION JUST COMMENT THE CELL AND EVERYTHING IS NORMAL\n",
        "# def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "#   df_train=pd.read_csv('train_paths_labels.csv')\n",
        "#   df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "#   datagen = ImageDataGenerator(  rescale=1./255,\n",
        "#     featurewise_center=True,  #CHANGED IT TO TRUE # set input mean to 0 over the dataset\n",
        "#     samplewise_center=False,  # set each sample mean to 0\n",
        "#     featurewise_std_normalization=True,  #CHANGED IT TO TRUE# divide inputs by std of the dataset\n",
        "#     samplewise_std_normalization=False,  # divide each input by its std\n",
        "#     zca_whitening=False,  # apply ZCA whitening\n",
        "#     rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#     width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "#     height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "#     horizontal_flip=True,  # randomly flip images\n",
        "#     vertical_flip=False,\n",
        "#     zoom_range=0.1,\n",
        "#     channel_shift_range=0.,\n",
        "#     fill_mode='nearest')\n",
        "  \n",
        "#   datagen.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "#   datagen.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "#   train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\",\n",
        "#                                               y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "#   valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\",\n",
        "#                                               y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "#   print(len(train_generator))\n",
        "#   print(\"making model\")\n",
        "#   if not os.path.isfile(model_file):\n",
        "#     model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "#   else:\n",
        "#     model= load_model(model_file, compile=False)\n",
        "  \n",
        "#   print(\"compiling\")\n",
        "#   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "#   checkpoint= ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "#   callbacks_list = [checkpoint]\n",
        "    \n",
        "#   step_train=train_generator.n//train_generator.batch_size\n",
        "#   step_valid=valid_generator.n//valid_generator.batch_size\n",
        "#   model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch,\n",
        "#                       validation_data=valid_generator, validation_steps=step_valid, shuffle=True,\n",
        "#                       verbose=verbose, callbacks=callbacks_list)\n",
        "#    #\n",
        "  \n",
        "  \n",
        "#   loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,steps=step_train)\n",
        "#   print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "#   loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,steps=step_valid)\n",
        "#   print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77y48PtKSdLz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SubModel/s Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "QENRLRsCkKvE",
        "colab_type": "code",
        "outputId": "f0ea6069-7140-46d9-ed70-2d539282d6dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dropbox-Uploader     log.txt  MURA-v1.1    train_paths_labels.csv\n",
            "dropbox_uploader.sh  models   sample_data  valid_paths_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uusJ6dlIjLzQ",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "2ddf85b1-6cf2-44cf-a627-04b1943135ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SubModel Evaluation { form-width: \"30%\" }\n",
        "model = 3 #@param {type:\"number\"}\n",
        "epoch = 3 #@param {type:\"integer\"}\n",
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "\n",
        "# No need now as I saved submodels and using them in ensemble model\n",
        "'''\n",
        "model_file= 'model_'+ models_names[model] +'.h5'\n",
        "\n",
        "p = mp.Process(target=watch_, args=(model_file,20))\n",
        "p.start()\n",
        "evaluate_limps(model=model,epoch=epoch,batch=batch_size,imagenet=True,freeze_all=False,verbose=1)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel_file= 'model_'+ models_names[model] +'.h5'\\n\\np = mp.Process(target=watch_, args=(model_file,20))\\np.start()\\nevaluate_limps(model=model,epoch=epoch,batch=batch_size,imagenet=True,freeze_all=False,verbose=1)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "ljRpA2shuet1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble Model\n",
        "### MobileNetV2 + DenseNet + Resnet50 (pretrained + downloaded from Dropbox)"
      ]
    },
    {
      "metadata": {
        "id": "eB7Q0lcYuXQz",
        "colab_type": "code",
        "outputId": "ff387512-6276-4981-b890-b54a57b0a6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "all_models = list()\n",
        "for i in listdir(dir):\n",
        " \n",
        "  if i == 'model_NASNetMobile.h5' or i == 'model_ensemble.h5':\n",
        "    continue\n",
        "    \n",
        "  filename = dir + i\n",
        "  # load model from file\n",
        "  model = load_model(filename)\n",
        "  # add to list of members\n",
        "  all_models.append(model)\n",
        "  print('loaded ',filename)\n",
        "\n",
        "def ensemble_model(all_models):\n",
        "  \n",
        "  for i in range(len(all_models)):\n",
        "    model = all_models[i]\n",
        "    for layer in model.layers:\n",
        "      # make not trainable\n",
        "      layer.trainable = False\n",
        "      # rename to avoid 'unique layer name' issue\n",
        "      layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        "  # define multi-headed input\n",
        "  ensemble_visible = [model.input for model in all_models]\n",
        "  # concatenate merge output from each model\n",
        "  ensemble_outputs = [model.output for model in all_models]\n",
        "  merge = concatenate(ensemble_outputs)\n",
        "  #print(merge.shape)\n",
        "  #merge = keras.layers.Permute((2,1))(merge)\n",
        "  #merge=keras.layers.Reshape((3,),dtype=tf.float32_ref)(merge)\n",
        "  hidden = Dense(128, activation='relu')(merge)\n",
        "  output = Dense(1, activation='sigmoid')(hidden)\n",
        "  model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  \n",
        "  # plot graph of ensemble\n",
        "  plot_model(model, show_shapes=True, to_file='ensemble_model_graph.png')\n",
        "  # compile\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded  models/model_InceptionV3.h5\n",
            "loaded  models/model_ResNet50.h5\n",
            "loaded  models/model_MobileNetV2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zj5DONfhEhmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@timer\n",
        "def eval_ensemble(model_file='model_ensemble.h5',epoch=3,batch=64,verbose=2):\n",
        "  \n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv')\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "  datagen=ImageDataGenerator(rescale=1./255)\n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\",\n",
        "                                              target_size=(224,224), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\",\n",
        "                                              target_size=(224,224), batch_size=batch)\n",
        "  \n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  \n",
        "  if not os.path.isfile(dir + model_file):\n",
        "    print(\"making ensemble model\")\n",
        "    model = ensemble_model(all_models)\n",
        "  else:\n",
        "    print(\"loading saved ensemble model\")\n",
        "    model= load_model(dir + model_file)\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(dir + model_file, monitor='val_loss', verbose=1, save_best_only=False,\n",
        "                              save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  \n",
        "  model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch, validation_data=valid_generator,\n",
        "                      validation_steps=step_valid, shuffle=True, verbose=verbose, callbacks=callbacks_list)\n",
        "  \n",
        "  \n",
        "  \n",
        "  loss_tr, accuracy_tr = model.evaluate_generator(train_generator, use_multiprocessing=True,workers=5,steps=step_train)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,workers=5,steps=step_valid)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nYYbTcHGI42",
        "colab_type": "code",
        "outputId": "ee19c50e-ff55-4aaa-cf1c-f7edba57e44d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1507
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SubModel Evaluation { form-width: \"30%\" }\n",
        "epoch = 3 #@param {type:\"integer\"}\n",
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "\n",
        "model_file= 'model_ensemble.h5'\n",
        "\n",
        "p = mp.Process(target=watch_, args=(model_file,20))\n",
        "p.start()\n",
        "eval_ensemble(model_file=model_file,epoch=3,batch=batch_size,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 36808 images belonging to 2 classes.\n",
            "Found 3197 images belonging to 2 classes.\n",
            "making ensemble model\n",
            "eval_ensemble executed in 0.02562319040298462  min/s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-accc81c1471a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatch_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0meval_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-b4ee0b2f2521>\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-8929b627044b>\u001b[0m in \u001b[0;36meval_ensemble\u001b[0;34m(model_file, epoch, batch, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"making ensemble model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading saved ensemble model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-96b0fa9ca952>\u001b[0m in \u001b[0;36mensemble_model\u001b[0;34m(all_models)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m#merge = keras.layers.Permute((2,1))(merge)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m#merge=keras.layers.Reshape((3,),dtype=tf.float32_ref)(merge)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensemble_visible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1987\u001b[0m       \u001b[0mare\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m   \"\"\"\n\u001b[0;32m-> 1989\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only one of transpose_a and adjoint_a can be True.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6023\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6024\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6025\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5662\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5663\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5664\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5665\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5666\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5599\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5600\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor(\"dense_1/kernel:0\", shape=(3, 128), dtype=float32_ref) must be from the same graph as Tensor(\"concat:0\", shape=(?, 3), dtype=float32)."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6h24yRz4_rts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}