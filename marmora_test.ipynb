{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mura_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimamd/Bone-Abnormality-Classifier-in-Keras/blob/Khaled-Branch/marmora_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "up1iA_3xOwax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
        "!unzip MURA-v1.1.zip\n",
        "!rm MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMY_KstJs079",
        "colab_type": "code",
        "outputId": "81e651d2-892e-41d6-9daf-0245f97e4a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall keras\n",
        "!pip3 install git+https://github.com/keras-team/keras\n",
        "!pip uninstall keras-preprocessing\n",
        "!pip3 install git+https://github.com/keras-team/keras-preprocessing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.2.4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/Keras-2.2.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/*\n",
            "    /usr/local/lib/python3.6/dist-packages/keras/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/md_autogen.py\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/update_docs.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-2.2.4\n",
            "Collecting git+https://github.com/keras-team/keras\n",
            "  Cloning https://github.com/keras-team/keras to /tmp/pip-req-build-s2r0p5f8\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: keras_applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.0.6)\n",
            "Requirement already satisfied: keras_preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.0.5)\n",
            "Building wheels for collected packages: Keras\n",
            "  Running setup.py bdist_wheel for Keras ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-vt6iqede/wheels/18/59/26/2a3c8d65212670e9526dcb6966eba15ee401e814aa74ca121d\n",
            "Successfully built Keras\n",
            "Installing collected packages: Keras\n",
            "Successfully installed Keras-2.2.4\n",
            "Uninstalling Keras-Preprocessing-1.0.5:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/Keras_Preprocessing-1.0.5.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/keras_preprocessing/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "Collecting git+https://github.com/keras-team/keras-preprocessing\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing to /tmp/pip-req-build-p_rayzk2\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-Preprocessing==1.0.5) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras-Preprocessing==1.0.5) (1.11.0)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Running setup.py bdist_wheel for Keras-Preprocessing ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-gsj3smxu/wheels/d5/b2/e4/de499da9d3a3120b4dfed9fc8580bedb35066713d8623e305d\n",
            "Successfully built Keras-Preprocessing\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X4I_XUYdSlH3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rdHciFEs2Fs",
        "colab_type": "code",
        "outputId": "f8c2d1ec-e608-4dd2-e0a5-f8243a3aa920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "# RESTART RUNTIME BEFORE PROCEEDING"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MURA-v1.1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D8ADE8fydpdM",
        "colab_type": "code",
        "outputId": "ff8be160-c1e5-4385-b6f5-61268f89506d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/70a2a39hiix6anm/train_paths_labels.csv\n",
        "!wget https://www.dropbox.com/s/8kfselmk1m3fphm/valid_paths_labels.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-15 23:37:07--  https://www.dropbox.com/s/70a2a39hiix6anm/train_paths_labels.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/70a2a39hiix6anm/train_paths_labels.csv [following]\n",
            "--2019-01-15 23:37:07--  https://www.dropbox.com/s/raw/70a2a39hiix6anm/train_paths_labels.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com/cd/0/inline/AZemCFM3jDSqFNjd5s0mgFI9hWRmO2SfrQ9w-O_XqBF_R6YCprZ8C82QvG-igvReiFbjzfXE4RZZRR2rvh4epc9RiUOQ1XFSUyciy3sq6f-4k1qcpKuBi_UzKvp0VG0LM5Ve7OiisFsrNm9dDvW24Mr5RgklPyOPMHNReXb9dVlRJe3jubp4xQHcX1tp6NpySFo/file [following]\n",
            "--2019-01-15 23:37:08--  https://uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com/cd/0/inline/AZemCFM3jDSqFNjd5s0mgFI9hWRmO2SfrQ9w-O_XqBF_R6YCprZ8C82QvG-igvReiFbjzfXE4RZZRR2rvh4epc9RiUOQ1XFSUyciy3sq6f-4k1qcpKuBi_UzKvp0VG0LM5Ve7OiisFsrNm9dDvW24Mr5RgklPyOPMHNReXb9dVlRJe3jubp4xQHcX1tp6NpySFo/file\n",
            "Resolving uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com (uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com (uc0a51ca077c9cf7cad4ef6d679f.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2497047 (2.4M) [text/plain]\n",
            "Saving to: ‘train_paths_labels.csv.1’\n",
            "\n",
            "train_paths_labels. 100%[===================>]   2.38M  13.4MB/s    in 0.2s    \n",
            "\n",
            "2019-01-15 23:37:08 (13.4 MB/s) - ‘train_paths_labels.csv.1’ saved [2497047/2497047]\n",
            "\n",
            "--2019-01-15 23:37:09--  https://www.dropbox.com/s/8kfselmk1m3fphm/valid_paths_labels.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/8kfselmk1m3fphm/valid_paths_labels.csv [following]\n",
            "--2019-01-15 23:37:09--  https://www.dropbox.com/s/raw/8kfselmk1m3fphm/valid_paths_labels.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com/cd/0/inline/AZfY7C3H865Yu8mRcVr57PRzsWGOhAtZ80h1outIrqkoXClmM9gT6CZ37KEgpiBMatbvk5uZ5LGXJywbKgtiFkJNzRwacjtkIIkT-SMWxzvDfB0icuQ85tbCnpF3otDEiAGrIDmJuz9sr0CZ3-qYp7HmOx1vWwccnRDFVBso9R5fuTU64cDWrcaaEFfa03Vudcw/file [following]\n",
            "--2019-01-15 23:37:10--  https://uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com/cd/0/inline/AZfY7C3H865Yu8mRcVr57PRzsWGOhAtZ80h1outIrqkoXClmM9gT6CZ37KEgpiBMatbvk5uZ5LGXJywbKgtiFkJNzRwacjtkIIkT-SMWxzvDfB0icuQ85tbCnpF3otDEiAGrIDmJuz9sr0CZ3-qYp7HmOx1vWwccnRDFVBso9R5fuTU64cDWrcaaEFfa03Vudcw/file\n",
            "Resolving uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com (uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com (uc3f7207a3e6c2057192f2b97d01.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217083 (212K) [text/plain]\n",
            "Saving to: ‘valid_paths_labels.csv.1’\n",
            "\n",
            "valid_paths_labels. 100%[===================>] 212.00K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-01-15 23:37:10 (6.04 MB/s) - ‘valid_paths_labels.csv.1’ saved [217083/217083]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ml6cgXJH7Eux",
        "colab_type": "code",
        "outputId": "029083f5-964b-47cc-a4c6-8023af2df399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -r Dropbox-Uploader\n",
        "!rm dropbox_uploader.sh\n",
        "!rm valid_paths_labels.csv\n",
        "!rm train_paths_labels.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Dropbox-Uploader': No such file or directory\n",
            "rm: cannot remove 'dropbox_uploader.sh': No such file or directory\n",
            "rm: cannot remove 'valid_paths_labels.csv': No such file or directory\n",
            "rm: cannot remove 'train_paths_labels.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T_91u16WOSr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, signal, shutil\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input,Flatten\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras import backend as K\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers.merge import concatenate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ez9S9xLB0yIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# onlyfiles = [f for f in listdir(\"MURA-v1.1\")]\n",
        "# print(onlyfiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N790OUoYiuDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SETUP"
      ]
    },
    {
      "metadata": {
        "id": "cTqlisSN_xe0",
        "colab_type": "code",
        "outputId": "0ea37a9a-fdac-44c5-e3f2-88a25a47f64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh download README.md"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bash: dropbox_uploader.sh: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_FjBSeR09-UZ",
        "colab_type": "code",
        "outputId": "80fab40a-1e79-4a17-d07c-feee875bdac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# just run the cell to be able to upload and download from Dropbox\n",
        "!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
        "!chmod +x Dropbox-Uploader/dropbox_uploader.sh\n",
        "source = 'Dropbox-Uploader'\n",
        "dest1 = '/content'\n",
        "shutil.move(source+'/'+'dropbox_uploader.sh', dest1)\n",
        "!echo \"EAQdVV4B6swAAAAAAAAMNeyKygEAA5FP7QaiPVRRgJwupFyPIyq0DaAP6LiVy23c\" > token.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dropbox-Uploader'...\n",
            "remote: Enumerating objects: 951, done.\u001b[K\n",
            "Receiving objects:   0% (1/951)   \rReceiving objects:   1% (10/951)   \rReceiving objects:   2% (20/951)   \rReceiving objects:   3% (29/951)   \rReceiving objects:   4% (39/951)   \rReceiving objects:   5% (48/951)   \rReceiving objects:   6% (58/951)   \rReceiving objects:   7% (67/951)   \rReceiving objects:   8% (77/951)   \rReceiving objects:   9% (86/951)   \rReceiving objects:  10% (96/951)   \rReceiving objects:  11% (105/951)   \rReceiving objects:  12% (115/951)   \rReceiving objects:  13% (124/951)   \rReceiving objects:  14% (134/951)   \rReceiving objects:  15% (143/951)   \rReceiving objects:  16% (153/951)   \rReceiving objects:  17% (162/951)   \rReceiving objects:  18% (172/951)   \rReceiving objects:  19% (181/951)   \rReceiving objects:  20% (191/951)   \rReceiving objects:  21% (200/951)   \rReceiving objects:  22% (210/951)   \rReceiving objects:  23% (219/951)   \rReceiving objects:  24% (229/951)   \rReceiving objects:  25% (238/951)   \rReceiving objects:  26% (248/951)   \rReceiving objects:  27% (257/951)   \rReceiving objects:  28% (267/951)   \rReceiving objects:  29% (276/951)   \rReceiving objects:  30% (286/951)   \rReceiving objects:  31% (295/951)   \rReceiving objects:  32% (305/951)   \rReceiving objects:  33% (314/951)   \rReceiving objects:  34% (324/951)   \rReceiving objects:  35% (333/951)   \rReceiving objects:  36% (343/951)   \rReceiving objects:  37% (352/951)   \rReceiving objects:  38% (362/951)   \rReceiving objects:  39% (371/951)   \rReceiving objects:  40% (381/951)   \rReceiving objects:  41% (390/951)   \rReceiving objects:  42% (400/951)   \rReceiving objects:  43% (409/951)   \rReceiving objects:  44% (419/951)   \rReceiving objects:  45% (428/951)   \rReceiving objects:  46% (438/951)   \rReceiving objects:  47% (447/951)   \rReceiving objects:  48% (457/951)   \rReceiving objects:  49% (466/951)   \rReceiving objects:  50% (476/951)   \rReceiving objects:  51% (486/951)   \rReceiving objects:  52% (495/951)   \rReceiving objects:  53% (505/951)   \rReceiving objects:  54% (514/951)   \rReceiving objects:  55% (524/951)   \rReceiving objects:  56% (533/951)   \rReceiving objects:  57% (543/951)   \rReceiving objects:  58% (552/951)   \rReceiving objects:  59% (562/951)   \rReceiving objects:  60% (571/951)   \rReceiving objects:  61% (581/951)   \rReceiving objects:  62% (590/951)   \rReceiving objects:  63% (600/951)   \rReceiving objects:  64% (609/951)   \rReceiving objects:  65% (619/951)   \rReceiving objects:  66% (628/951)   \rReceiving objects:  67% (638/951)   \rReceiving objects:  68% (647/951)   \rReceiving objects:  69% (657/951)   \rReceiving objects:  70% (666/951)   \rReceiving objects:  71% (676/951)   \rReceiving objects:  72% (685/951)   \rReceiving objects:  73% (695/951)   \rReceiving objects:  74% (704/951)   \rReceiving objects:  75% (714/951)   \rReceiving objects:  76% (723/951)   \rReceiving objects:  77% (733/951)   \rReceiving objects:  78% (742/951)   \rremote: Total 951 (delta 0), reused 0 (delta 0), pack-reused 951\u001b[K\n",
            "Receiving objects:  79% (752/951)   \rReceiving objects:  80% (761/951)   \rReceiving objects:  81% (771/951)   \rReceiving objects:  82% (780/951)   \rReceiving objects:  83% (790/951)   \rReceiving objects:  84% (799/951)   \rReceiving objects:  85% (809/951)   \rReceiving objects:  86% (818/951)   \rReceiving objects:  87% (828/951)   \rReceiving objects:  88% (837/951)   \rReceiving objects:  89% (847/951)   \rReceiving objects:  90% (856/951)   \rReceiving objects:  91% (866/951)   \rReceiving objects:  92% (875/951)   \rReceiving objects:  93% (885/951)   \rReceiving objects:  94% (894/951)   \rReceiving objects:  95% (904/951)   \rReceiving objects:  96% (913/951)   \rReceiving objects:  97% (923/951)   \rReceiving objects:  98% (932/951)   \rReceiving objects:  99% (942/951)   \rReceiving objects: 100% (951/951)   \rReceiving objects: 100% (951/951), 318.69 KiB | 3.25 MiB/s, done.\n",
            "Resolving deltas:   0% (0/506)   \rResolving deltas:   5% (26/506)   \rResolving deltas:   6% (31/506)   \rResolving deltas:   9% (49/506)   \rResolving deltas:  11% (58/506)   \rResolving deltas:  19% (99/506)   \rResolving deltas:  38% (197/506)   \rResolving deltas:  46% (235/506)   \rResolving deltas:  51% (260/506)   \rResolving deltas:  52% (266/506)   \rResolving deltas:  59% (300/506)   \rResolving deltas:  62% (318/506)   \rResolving deltas:  64% (327/506)   \rResolving deltas:  66% (338/506)   \rResolving deltas:  68% (346/506)   \rResolving deltas:  69% (352/506)   \rResolving deltas:  75% (382/506)   \rResolving deltas:  79% (400/506)   \rResolving deltas:  80% (409/506)   \rResolving deltas:  81% (414/506)   \rResolving deltas:  83% (421/506)   \rResolving deltas:  84% (430/506)   \rResolving deltas:  85% (431/506)   \rResolving deltas:  88% (448/506)   \rResolving deltas:  91% (463/506)   \rResolving deltas: 100% (506/506)   \rResolving deltas: 100% (506/506), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iBG6GG75QHwc",
        "colab_type": "code",
        "outputId": "177001ac-8445-41da-b884-5c0d58e54ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# download train and valid csv files that include images path and their labels\n",
        "!bash dropbox_uploader.sh download train_paths_labels.csv\n",
        "!bash dropbox_uploader.sh download valid_paths_labels.csv\n",
        "# the saved model file\n",
        "model_file= 'model.h5'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " This is the first time you run this script, please follow the instructions:\n",
            "\n",
            " 1) Open the following URL in your Browser, and log in using your account: https://www.dropbox.com/developers/apps\n",
            " 2) Click on \"Create App\", then select \"Dropbox API app\"\n",
            " 3) Now go on with the configuration, choosing the app permissions and access restrictions to your DropBox folder\n",
            " 4) Enter the \"App Name\" that you prefer (e.g. MyUploader104042190512454)\n",
            "\n",
            " Now, click on the \"Create App\" button.\n",
            "\n",
            " When your new App is successfully created, please click on the Generate button\n",
            " under the 'Generated access token' section, then execute the following command:\n",
            "\n",
            " echo \"INPUT_YOUR_ACCESS_TOKEN_HERE\" > token.txt\n",
            "\n",
            "\n",
            " Found token.txt with access token: EAQdVV4B6swAAAAAAAAMNeyKygEAA5FP7QaiPVRRgJwupFyPIyq0DaAP6LiVy23c\n",
            "\n",
            " You can unlink this account if the token is wrong, using:\n",
            " ./dropbox-uploader.sh unlink\n",
            "\n",
            " The configuration has been saved.\n",
            " > No such file or directory: /valid_paths_labels.csv\n",
            "Some error occured. Please check the log.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Cu15H_TCAVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# watch_ monitors the state of certain file if it is modified and uploads it to Dropbox if so\n",
        "def watch_(file, interval):\n",
        "  from datetime import datetime\n",
        "  first_Time=False\n",
        "  while True:\n",
        "    if os.path.isfile(file):\n",
        "      if not first_Time:\n",
        "        os.system(\"bash dropbox_uploader.sh upload \"+file+\" \"+file)\n",
        "        first_Time=True\n",
        "      moddate = os.stat(file)[8]\n",
        "      time.sleep(interval)\n",
        "      moddate_ = os.stat(file)[8]\n",
        "      if moddate < moddate_:\n",
        "        os.system(\"bash dropbox_uploader.sh upload \"+file+\" \"+file)\n",
        "    else:\n",
        "      time.sleep(interval)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbXWb8jCVsGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ]
    },
    {
      "metadata": {
        "id": "4Y4fjRr9Vwl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  #weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  #default because refrenced before assignment error, just scroll down\n",
        "  base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  feature_Concatenation_model1=NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  feature_Concatenation_model2=MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "#   feature_Concatenation_Merged=None\n",
        "  #initializing pretrained model\n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 3):\n",
        "    base_model = ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False)   \n",
        "  elif (base == 4):\n",
        "    base_model = NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 5): #Feature concatenated\n",
        "    base_model = feature_Concatenation_Merged   \n",
        " \n",
        "  if (freeze_all):\n",
        "    #freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "\n",
        "\n",
        "  if(add_denses):\n",
        "    \n",
        "\n",
        "    if(base ==5):  #Feature concatenated\n",
        "      \n",
        "      print(\"Adding bases\")\n",
        "\n",
        "      x1 = feature_Concatenation_model1.output\n",
        "      x1 = GlobalAveragePooling2D()(x1)\n",
        "   \n",
        "      x2 = feature_Concatenation_model2.output\n",
        "      x2 = GlobalAveragePooling2D()(x2)\n",
        "      \n",
        "\n",
        " \n",
        "\n",
        "      merge = concatenate([x1, x2])\n",
        "      \n",
        "      \n",
        "      merge = Dense(512, activation='relu')(merge)\n",
        "      merge = Dense(128, activation='relu')(merge)\n",
        "      \n",
        "      predictions = Dense(1, activation='sigmoid')(merge)\n",
        "      \n",
        "      print(\"Model Creation\")\n",
        "\n",
        "      feature_Concatenation_Merged = Model(inputs=[feature_Concatenation_model1.input,feature_Concatenation_model2.input],outputs=predictions)\n",
        "      model= feature_Concatenation_Merged\n",
        "      print(\"all here done\")\n",
        "\n",
        "      \n",
        "    else:\n",
        "            \n",
        "      # add a global spatial average pooling layer\n",
        "      x = base_model.output\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      # let's add a fully-connected layer\n",
        "      #x = Dense(1024, activation='relu')(x)\n",
        "      x = Dense(512, activation='relu')(x)\n",
        "      x = Dense(128, activation='relu')(x)\n",
        "      #x = Dense(32, activation='relu')(x)\n",
        "      # and a logistic layer -- let's say we have 200 classes\n",
        "\n",
        "      predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "      # this is the model we will train\n",
        "      model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # just feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  plot_model(model,to_file='demo.png',show_shapes=True)\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2nG7OGT2iwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "bug: if called fn on another base model it still loads the model"
      ]
    },
    {
      "metadata": {
        "id": "bEX9fTsAO5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#KAREEM'S COPY OF FUNCTION JUST COMMENT THE CELL AND EVERYTHING IS NORMAL\n",
        "def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2):\n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv')\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv')\n",
        "  \n",
        "  datagen = ImageDataGenerator(  rescale=1./255,\n",
        "    featurewise_center=True,  #CHANGED IT TO TRUE # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=True,  #CHANGED IT TO TRUE# divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.1,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode='nearest')\n",
        "  \n",
        "  datagen.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  datagen.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  print(len(train_generator))\n",
        "  print(\"making model\")\n",
        "  if not os.path.isfile(model_file):\n",
        "    model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "  else:\n",
        "    model= load_model(model_file, compile=False)\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch,\n",
        "                      validation_data=valid_generator, validation_steps=step_valid, shuffle=True,\n",
        "                      verbose=verbose, callbacks=callbacks_list)\n",
        "   #\n",
        "  \n",
        "  \n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True,steps=step_train)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,steps=step_valid)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxzeaLRCIIlf",
        "colab_type": "code",
        "outputId": "dbe84152-fbbd-4175-9b78-1c45521271cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!rm model.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'model.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QENRLRsCkKvE",
        "colab_type": "code",
        "outputId": "dd8688a3-35ce-47d0-fe53-3b98e62d94a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dropbox-Uploader     MURA-v1.1\t    sample_data  train_paths_labels.csv\n",
            "dropbox_uploader.sh  MURA-v1.1.zip  token.txt\t valid_paths_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uusJ6dlIjLzQ",
        "colab_type": "code",
        "outputId": "975b6b2e-76a9-4e10-c4ea-d1f4cabc9af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        }
      },
      "cell_type": "code",
      "source": [
        "p = mp.Process(target=watch_, args=(model_file,5))\n",
        "p.start()\n",
        "evaluate_limps(model=5,epoch=1,batch=32,imagenet=True,freeze_all=False,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 36808 images belonging to 2 classes.\n",
            "Found 3197 images belonging to 2 classes.\n",
            "1151\n",
            "making model\n",
            "Adding bases\n",
            "First Dense\n",
            "Secomd Dense\n",
            "Meging Dense\n",
            "Model Creation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-99eab85e9e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatch_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_limps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreeze_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-95f4bc78464a>\u001b[0m in \u001b[0;36mevaluate_limps\u001b[0;34m(model, epoch, batch, imagenet, freeze_all, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"making model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_FT_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagenet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_denses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-83e9c49bd184>\u001b[0m in \u001b[0;36mmake_FT_model\u001b[0;34m(base, imagenet, freeze_all, add_denses)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Creation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       \u001b[0mfeature_Concatenation_Merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_Concatenation_model1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_Concatenation_model2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeature_Concatenation_Merged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all here done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    157\u001b[0m                                  \u001b[0;34m'must come from `keras.layers.Input`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                  \u001b[0;34m'Received: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                                  ' (missing previous layer metadata).')\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input tensors to a Model must come from `keras.layers.Input`. Received: <keras.engine.training.Model object at 0x7f5d87c54c50> (missing previous layer metadata)."
          ]
        }
      ]
    }
  ]
}