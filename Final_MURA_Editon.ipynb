{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Ensemble_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimamd/Bone-Abnormality-Classifier-in-Keras/blob/Khaled-Branch/Final_MURA_Editon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rqKkS-8bOKTi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "metadata": {
        "id": "aSIN7tUZefiL",
        "colab_type": "code",
        "outputId": "4c1e68e4-0218-4c42-b157-a743b7f8446a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "up1iA_3xOwax",
        "colab_type": "code",
        "outputId": "eb8220a3-fb77-45c0-df88-8d5d9afd4c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-21 00:00:48--  https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380245855 (3.1G) [application/zip]\n",
            "Saving to: ‘MURA-v1.1.zip’\n",
            "\n",
            "MURA-v1.1.zip       100%[===================>]   3.15G  88.0MB/s    in 38s     \n",
            "\n",
            "2019-01-21 00:01:27 (83.9 MB/s) - ‘MURA-v1.1.zip’ saved [3380245855/3380245855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c1q30MNoZrZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import zipfile\n",
        "import time\n",
        "import concurrent.futures\n",
        "\n",
        "# timer func evaluates func/s running time in minutes\n",
        "def timer(f):\n",
        "\n",
        "    def inner(*args, **kwargs):\n",
        "        try:\n",
        "            t0 = time.time()\n",
        "            return f(*args, **kwargs)\n",
        "        finally:\n",
        "            t1 = time.time()\n",
        "            print(f.__name__, 'executed in', (t1 - t0) / 60, ' min/s')\n",
        "\n",
        "    return inner\n",
        "\n",
        "# fast unzip, usually 900% faster than normal \"unzip\" command\n",
        "# thanks to Peter Bengtsson <3: https://www.peterbe.com/\n",
        "\n",
        "@timer\n",
        "def fast_unzip(fn, dest):\n",
        "\n",
        "    def unzip_member(zf, name, dest):\n",
        "        while True:\n",
        "            try:\n",
        "                zf.extract(name, dest)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                if e.errno != os.errno.EEXIST:\n",
        "                    raise\n",
        "                time.sleep(2)\n",
        "                pass\n",
        "\n",
        "    with open(fn, 'rb') as f:\n",
        "        zf = zipfile.ZipFile(f)\n",
        "        futures = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            for member in zf.infolist():\n",
        "                futures.append(executor.submit(unzip_member, zf,\n",
        "                               member.filename, dest))\n",
        "\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-JgkBnialez",
        "colab_type": "code",
        "outputId": "ea072af1-95fe-4a56-afde-c494b2ce402a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fast_unzip('MURA-v1.1.zip','/content')\n",
        "!rm MURA-v1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fast_unzip executed in 0.8417939861615499  min/s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DMY_KstJs079",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall keras -y\n",
        "!pip3 install git+https://github.com/keras-team/keras\n",
        "!pip uninstall keras-preprocessing -y\n",
        "!pip3 install git+https://github.com/keras-team/keras-preprocessing \n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rdHciFEs2Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # to force restart runtime\n",
        "# def restart_runtime():\n",
        "#   os.kill(os.getpid(), 9)\n",
        "  \n",
        "# try:\n",
        "#     restart_runtime\n",
        "# except NameError:\n",
        "#     print(\"already restarted!\")\n",
        "# else:\n",
        "#     restart_runtime()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_91u16WOSr3",
        "colab_type": "code",
        "outputId": "6089a1b9-5450-44a3-a00a-7775a3cf0ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, signal, shutil\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard)\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.metrics import binary_accuracy, binary_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.preprocessing import image as k_im_prep\n",
        "from keras import backend as K\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "from keras.utils import plot_model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Elt6blzj0a3",
        "colab_type": "code",
        "outputId": "6c368517-ae3e-4809-ac9f-c9f9186c1184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total_size = 0\n",
        "# to get size of certain directory\n",
        "for path, dirs, files in os.walk('MURA-v1.1'):\n",
        "    for f in files:\n",
        "        fp = os.path.join(path, f)\n",
        "        total_size += os.path.getsize(fp)\n",
        "print(\"Directory size: \" + str(total_size/1024**3) + \" (Gigabyte)\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory size: 3.1397332791239023 (Gigabyte)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SgFz9AwaBzBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Directory of saved models { form-width: \"30%\", display-mode: \"both\" }\n",
        "\n",
        "''' select \"unique name\" for \"your\" models directory where pre-trained/saved\n",
        "models will be uploaded to Dropbox if you want to apply any modifications \n",
        "such as preprocessing '''\n",
        "\n",
        "dir = \"models_aug\" #@param {type:\"string\"}\n",
        "dir = dir + \"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N790OUoYiuDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SETUP \n",
        "### just run all cells in this section"
      ]
    },
    {
      "metadata": {
        "id": "cPmbRbg74crN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drivee=\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_FjBSeR09-UZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # just run the cell to be able to upload and download from Dropbox\n",
        "# !git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
        "# !chmod +x Dropbox-Uploader/dropbox_uploader.sh\n",
        "# source = 'Dropbox-Uploader'\n",
        "# dest1 = '/content'\n",
        "# shutil.move(source+'/'+'dropbox_uploader.sh', dest1)\n",
        "# !echo \"pzFqTa1uWVAAAAAAAAAACtGcVohdBzoFRrwtLYsQCxhD9a7IjevvuOTNV8OWB2LX\" > token.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTqlisSN_xe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!bash dropbox_uploader.sh download README.md > log.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBG6GG75QHwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # download train and valid csv files that include images path and their labels\n",
        "# !bash dropbox_uploader.sh -p download /labels_csv/train_paths_labels.csv\n",
        "# !bash dropbox_uploader.sh -p download /labels_csv/valid_paths_labels.csv\n",
        "\n",
        "# # create folder of pre-trained/saved models if it doesn't exist\n",
        "# os.system(\"bash dropbox_uploader.sh mkdir /\"+ dir[:-1] +\" > log.txt\")\n",
        "\n",
        "# # download folder of pre-trained/saved models\n",
        "# os.system(\"bash dropbox_uploader.sh download \"+ dir[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Cu15H_TCAVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# watch_ monitors the state of certain file if it is modified and uploads it to Dropbox if so\n",
        "def watch_(file, interval):\n",
        "    first_Time = False\n",
        "    while True:\n",
        "        if os.path.isfile(dir + file):\n",
        "            if not first_Time:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "                first_Time = True\n",
        "                \n",
        "            moddate = os.stat(dir + file)[8]\n",
        "            time.sleep(interval)\n",
        "            moddate_ = os.stat(dir + file)[8]\n",
        "            \n",
        "            if moddate < moddate_:\n",
        "                os.system('bash dropbox_uploader.sh upload ' + dir\n",
        "                          + file + ' ' + dir + file)\n",
        "        else:\n",
        "            time.sleep(interval)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8YIedbMKPj4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix setup"
      ]
    },
    {
      "metadata": {
        "id": "lckhF_XQeLN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KEcCuFNP0TAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_matrix_multiples(cnf_matrix,Name):\n",
        "  \n",
        "  np.set_printoptions(precision=2)\n",
        "\n",
        "  cm_class_label = ['Normal','abnormal']\n",
        "  # Plot non-normalized confusion matrix\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(cnf_matrix,cm_class_label,title=Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYjo-6DBFJbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def paths_n_labels(csv):\n",
        "    #make dataframe\n",
        "    print(csv)\n",
        "    studies=pd.read_csv(csv, sep=',',header=None)\n",
        "    #separate study paths and labels of given limp from those of other limps\n",
        "    limp_studies=studies[studies[0].str.contains(\"Khalodaaa\")==False]\n",
        "    #make it a numpy\n",
        "    limp_studies=np.array(limp_studies)\n",
        "    #limp study folder paths\n",
        "    limp_paths=[]\n",
        "    #labels of given limp\n",
        "    limp_labels=[]\n",
        "    for i in tqdm( range(limp_studies.shape[0]) ):\n",
        "        study_path= drivee + limp_studies[i][0]\n",
        "        study_label=limp_studies[i][1]\n",
        "        study_files = [f for f in listdir(study_path) if isfile(join(study_path, f))]\n",
        "        for image in study_files:\n",
        "            limp_paths.append(study_path + image)\n",
        "            limp_labels.append(study_label)\n",
        "\n",
        "    limp_paths=np.array(limp_paths)\n",
        "    limp_labels=np.array(limp_labels)\n",
        "\n",
        "    return limp_paths,limp_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0wPLQsDFexB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_images(paths ,targ_size= (224, 224)):\n",
        "    images=[]\n",
        "    #load any limp images\n",
        "    for path in tqdm(paths):\n",
        "        img=k_im_prep.load_img(path, target_size=targ_size )\n",
        "        images.append(np.array(img))\n",
        "\n",
        "    #making it a numpy array instead of python list\n",
        "    return (np.array(images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbXWb8jCVsGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ]
    },
    {
      "metadata": {
        "id": "4Y4fjRr9Vwl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_FT_model(base=1, imagenet=True, freeze_all=True, add_denses=True):\n",
        "  \n",
        "  #weights of pretrained model\n",
        "  if (imagenet==True):\n",
        "    w='imagenet'\n",
        "  else:\n",
        "    w=None\n",
        "  \n",
        "  #default because refrenced before assignment error, just scroll down\n",
        "  base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "\n",
        "#   feature_Concatenation_Merged=None\n",
        "  #initializing pretrained model\n",
        "  \n",
        "  print(\"Choose model is\",base)\n",
        "  \n",
        "  if (base==0):\n",
        "    base_model = MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 1):\n",
        "    base_model = DenseNet169(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 2):\n",
        "    base_model = InceptionV3(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 3):\n",
        "    base_model = ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False)   \n",
        "  elif (base == 4):\n",
        "    base_model = NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False)\n",
        "  elif (base == 6): #Feature concatenated model\n",
        "    base_model_new = Input(shape= (224, 224, 3))  \n",
        " \n",
        "  if (freeze_all):\n",
        "    #freeze layers of densenet\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable= False \n",
        "  \n",
        "\n",
        "\n",
        "  if(add_denses):\n",
        "    \n",
        "\n",
        "    if(base ==6):  #Feature concatenated\n",
        "      \n",
        "      print(\"Adding bases\")\n",
        "      feature_Concatenation_model1=NASNetMobile(input_shape= (224, 224, 3),weights=w, include_top=False, input_tensor=base_model_new)\n",
        "      feature_Concatenation_model2=MobileNetV2(input_shape= (224, 224, 3),weights=w, include_top=False, input_tensor=base_model_new)\n",
        "      feature_Concatenation_model3=ResNet50(input_shape= (224, 224, 3),weights=w, include_top=False, input_tensor=base_model_new)\n",
        "\n",
        "      x1 = feature_Concatenation_model1.output\n",
        "      x1 = GlobalAveragePooling2D()(x1)\n",
        "   \n",
        "      x2 = feature_Concatenation_model2.output\n",
        "      x2 = GlobalAveragePooling2D()(x2)\n",
        "      \n",
        "      x3 = feature_Concatenation_model2.output\n",
        "      x3 = GlobalAveragePooling2D()(x3)\n",
        "      \n",
        " \n",
        "\n",
        "      merge = concatenate([x1, x2, x3])\n",
        "      \n",
        "      \n",
        "      merge = Dense(512, activation='relu')(merge)\n",
        "      merge = Dense(128, activation='relu')(merge)\n",
        "      \n",
        "      predictions = Dense(1, activation='sigmoid')(merge)\n",
        "      \n",
        "      print(\"Model Creation\")\n",
        "\n",
        "      feature_Concatenation_Merged = Model(inputs=[base_model_new],outputs=predictions)\n",
        "      model= feature_Concatenation_Merged\n",
        "      print(\"all here done\")\n",
        "\n",
        "      \n",
        "    else:\n",
        "            \n",
        "      # add a global spatial average pooling layer\n",
        "      x = base_model.output\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      \n",
        "      # let's add a fully-connected layer\n",
        "      #x = Dense(1024, activation='relu')(x)\n",
        "      x = Dense(512, activation='relu')(x)\n",
        "      x = Dense(128, activation='relu')(x)\n",
        "      #x = Dense(32, activation='relu')(x)\n",
        "      # and a logistic layer -- let's say we have 200 classes\n",
        "\n",
        "      predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "      # this is the model we will train\n",
        "      model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "  else:\n",
        "    # just feature extractor\n",
        "    model = Model(inputs=base_model.input, output=x)\n",
        "  \n",
        "  \n",
        "  plot_model(model,to_file='ModelGraph.png',show_shapes=True)\n",
        "#   print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzAiJSX0TX-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_names=['MobileNetV2','DenseNet169','InceptionV3','ResNet50','NASNetMobile','Xception','Feature_Conct']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Atw91wISar9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation function"
      ]
    },
    {
      "metadata": {
        "id": "bEX9fTsAO5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#KAREEM'S COPY OF FUNCTION JUST COMMENT THE CELL AND EVERYTHING IS NORMAL\n",
        "def evaluate_limps(model=1,epoch=5,batch=32, imagenet=True, freeze_all=False,verbose=2,require_fitting=False):\n",
        " \n",
        "  \n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv',converters={'Label': str})\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv',converters={'Label': str})\n",
        "  model_file= 'model_'+models_names[model]+'.h5'\n",
        "  \n",
        "  datagen = ImageDataGenerator(  rescale=1./255,\n",
        "    featurewise_center=True,  #CHANGED IT TO TRUE # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=True,  #CHANGED IT TO TRUE# divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.1,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode='nearest')\n",
        "  \n",
        "  datagen.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  datagen.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "  \n",
        "  \n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=None,x_col=\"Img_Path\",\n",
        "                                              y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch)\n",
        "  \n",
        "  \n",
        "  if not os.path.isfile(dir+model_file):\n",
        "    print(\"making model\")\n",
        "    model=make_FT_model(base= model, imagenet=imagenet, freeze_all=freeze_all, add_denses=True)\n",
        "  else:\n",
        "    print(\"loading model\")\n",
        "    model= load_model(dir+model_file, compile=False)\n",
        "    require_fitting = False\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(dir+model_file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  step_train=train_generator.n//train_generator.batch_size\n",
        "  step_valid=valid_generator.n//valid_generator.batch_size\n",
        "  \n",
        "  if require_fitting:\n",
        "    model.fit_generator(generator=train_generator, steps_per_epoch=step_train, epochs=epoch,\n",
        "                        validation_data=valid_generator, validation_steps=step_valid, shuffle=True,\n",
        "                        verbose=verbose, callbacks=callbacks_list)\n",
        "   \n",
        "  \n",
        "  \n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(train_generator, use_multiprocessing=True, workers=10,steps=step_train,verbose=1)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(valid_generator, use_multiprocessing=True,workers=10,steps=step_valid,verbose=1)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljRpA2shuet1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble Model\n",
        "### MobileNetV2 + InceptionV3 + Resnet50 (pretrained + downloaded from Dropbox)"
      ]
    },
    {
      "metadata": {
        "id": "7Jo_KBK1qiY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_three_inputs(gen, df, batch_size):\n",
        "  generator=gen.flow_from_dataframe(dataframe=df, directory=None,x_col=\"Img_Path\", y_col=\"Label\", class_mode=\"binary\", target_size=(224,224), batch_size=batch_size)\n",
        "  while True:\n",
        "    gen_xy= generator.next()\n",
        "    yield [gen_xy[0], gen_xy[0], gen_xy[0]], gen_xy[1]\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbEz3Y6Z7ZkS",
        "colab_type": "code",
        "outputId": "13932920-b1d4-48c7-9461-f1819a8fbc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "all_models = list()\n",
        "for i in listdir(dir):\n",
        "\n",
        "  if i == 'model_NASNetMobile.h5' or i == 'model_ensemble.h5':\n",
        "    continue\n",
        "\n",
        "  filename = dir + i\n",
        "  # load model from file\n",
        "  model = load_model(filename)\n",
        "  # add to list of members\n",
        "  all_models.append(model)\n",
        "  print('loaded ',filename)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded  models_aug/model_InceptionV3.h5\n",
            "loaded  models_aug/model_ResNet50.h5\n",
            "loaded  models_aug/model_MobileNetV2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zj5DONfhEhmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "@timer\n",
        "def eval_ensemble(model_file='model_ensemble.h5',epoch=3,batch=64,verbose=2,require_fitting=False):\n",
        "  \n",
        "  \n",
        "  df_train=pd.read_csv('train_paths_labels.csv',converters={'Label': str})\n",
        "  df_valid=pd.read_csv('valid_paths_labels.csv',converters={'Label': str})\n",
        "  \n",
        "  \n",
        "  if not os.path.isfile(dir + model_file):\n",
        "    print(\"making ensemble model\")\n",
        "    for i in range(len(all_models)):\n",
        "      model = all_models[i]\n",
        "      for layer in model.layers:\n",
        "        # make not trainable\n",
        "        layer.trainable = False\n",
        "        # rename to avoid 'unique layer name' issue\n",
        "        layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        "    # define multi-headed input\n",
        "    ensemble_visible = [model.input for model in all_models]\n",
        "    # concatenate merge output from each model\n",
        "    ensemble_outputs = [model.output for model in all_models]\n",
        "    merge = concatenate(ensemble_outputs)\n",
        "\n",
        "    hidden = Dense(128, activation='relu')(merge)\n",
        "    output = Dense(1, activation='sigmoid')(hidden)\n",
        "    model = Model(inputs=ensemble_visible, outputs=output)\n",
        "  else:\n",
        "    print(\"loading saved ensemble model\")\n",
        "    model= load_model(dir + model_file)\n",
        "    require_fitting = False\n",
        "  \n",
        "  print(\"compiling\")\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint= ModelCheckpoint(dir + model_file, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                              save_weights_only=False, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint]\n",
        "    \n",
        "  \n",
        "\n",
        "  datagen=ImageDataGenerator(rescale=1./255)\n",
        "  \n",
        "  step_train=len(df_train.index)//batch\n",
        "  step_valid=len(df_valid.index)//batch\n",
        "  \n",
        "  if require_fitting:\n",
        "    model.fit_generator(generator=gen_three_inputs(datagen, df_train, batch), steps_per_epoch=step_train, epochs=epoch, shuffle=True, verbose=verbose)\n",
        "  \n",
        "  loss_tr, accuracy_tr =model.evaluate_generator(generator=gen_three_inputs(datagen, df_train, batch), use_multiprocessing=True,steps=step_train, verbose=1)\n",
        "  print(\"training loss/accuracy: \", loss_tr,'/', accuracy_tr)\n",
        "\n",
        "  loss_val, accuracy_val = model.evaluate_generator(generator=gen_three_inputs(datagen, df_valid, batch), use_multiprocessing=True,steps=step_valid, verbose=1)\n",
        "  print(\"validation loss/accuracy: \", loss_val,'/', accuracy_val)\n",
        "\n",
        "  return model,datagen,df_train,df_valid\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81Z7UL84-0SL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gWo7yaSRqbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reporting"
      ]
    },
    {
      "metadata": {
        "id": "OFqgzmY14YWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Report_Model():\n",
        "  \n",
        "\n",
        "  #Confession matrix part\n",
        "   ###########################################\n",
        "\n",
        "  num_of_test_samples=3197\n",
        "  train_studies=drivee+'MURA-v1.1/train_labeled_studies.csv'\n",
        "  valid_studies=drivee+'MURA-v1.1/valid_labeled_studies.csv'\n",
        "\n",
        "\n",
        "  valid_paths,valid_labels=paths_n_labels(valid_studies)\n",
        "  #   train_paths,train_labels=paths_n_labels(train_studies)\n",
        "\n",
        "  #   train_imgs= read_images(train_paths)\n",
        "  valid_imgs= read_images(valid_paths)\n",
        "\n",
        "\n",
        "\n",
        "  y_pred=model.predict([valid_imgs for _ in range(3)])\n",
        "  y_pred[y_pred >=0.5]=1\n",
        "  y_pred[y_pred <0.5]=0\n",
        "\n",
        "\n",
        "  #   y_pred_for_training=model.predict(train_imgs)\n",
        "  #   y_pred_for_training[y_pred_for_training >=0.5]=1\n",
        "  #   y_pred_for_training[y_pred_for_training < 0.5]=0\n",
        "\n",
        "\n",
        "  print(y_pred)\n",
        "\n",
        "  # Compute confusion matrix\n",
        "  cnf_matrix = confusion_matrix(valid_labels, y_pred)\n",
        "\n",
        "  #   cnf_matrix2 = confusion_matrix(train_labels, y_pred_for_training)\n",
        "\n",
        "  plot_matrix_multiples(cnf_matrix,Name='Confusion matrix for valiadation set')\n",
        "\n",
        "  #   plot_matrix_multiples(cnf_matrix2,Name='Confusion matrix for training set')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "03A_91SIQ16j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run Cell"
      ]
    },
    {
      "metadata": {
        "id": "4nYYbTcHGI42",
        "colab_type": "code",
        "outputId": "445445a7-31ca-4dfe-fb68-09b1721e3a71",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SubModel Evaluation { form-width: \"30%\" }\n",
        "epoch = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "batch_size = 32 #@param {type:\"slider\", min:16, max:128, step:16}\n",
        "model_chosen = \"Feature_Conct\" #@param [\"MobileNetV2\", \"DenseNet169\", \"InceptionV3\", \"ResNet50\", \"NASNetMobile\", \"Xception\", \"Feature_Conct\", \"Ensemble\"] {allow-input: true}\n",
        "Report = True #@param {type:\"boolean\"}\n",
        "require_fitting = False #@param {type:\"boolean\"}\n",
        "model_no=-1\n",
        "model_file=-1\n",
        "\n",
        "if(model_chosen==\"MobileNetV2\"):\n",
        "    model_no=0\n",
        "elif model_chosen==\"DenseNet169\":\n",
        "    model_no=1\n",
        "elif model_chosen== \"InceptionV3\":\n",
        "    model_no=2\n",
        "elif model_chosen==\"ResNet50\":\n",
        "    model_no=3\n",
        "elif model_chosen==\"NASNetMobile\":\n",
        "    model_no=4\n",
        "elif model_chosen==\"Xception\":\n",
        "    model_no=5\n",
        "elif model_chosen==\"Feature_Conct\":\n",
        "    model_no=6\n",
        "\n",
        "\n",
        "\n",
        "print(model_no)\n",
        "\n",
        "if(model_chosen==\"Ensemble\"):\n",
        "  model_file= 'model_ensemble.h5'\n",
        "  p = mp.Process(target=watch_, args=(model_file,20))\n",
        "  p.start()\n",
        "  model,datagen,df_train,df_valid=eval_ensemble(model_file=model_file,\n",
        "                                                epoch=epoch,batch=batch_size,verbose=1,require_fitting=require_fitting)\n",
        "\n",
        "  \n",
        "else:\n",
        "  p = mp.Process(target=watch_, args=(model_file,20))\n",
        "  p.start()\n",
        "  evaluate_limps(model=model_no,epoch=epoch,batch=batch_size,imagenet=True,freeze_all=False,verbose=1,require_fitting=require_fitting)\n",
        "\n",
        "\n",
        "if(Report):\n",
        "  Report_Model()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-8:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-6-09cd126c6312>\", line 4, in watch_\n",
            "    if os.path.isfile(dir + file):\n",
            "TypeError: must be str, not int\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 36808 images belonging to 2 classes.\n",
            "Found 3197 images belonging to 2 classes.\n",
            "making model\n",
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n",
            "Choose model is 6\n",
            "Adding bases\n",
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5\n",
            "19996672/19993432 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}